<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=0.8"/><title>4&nbsp;Neural Networks</title><link rel="stylesheet" type="text/css" href="scribble.css" title="default"/><link rel="stylesheet" type="text/css" href="racket.css" title="default"/><link rel="stylesheet" type="text/css" href="figure.css" title="default"/><link rel="stylesheet" type="text/css" href="autobib.css" title="default"/><link rel="stylesheet" type="text/css" href="scribble-style.css" title="default"/><script type="text/javascript" src="scribble-common.js"></script><script type="text/javascript" src="figure.js"></script><script type="text/javascript">
(function() {document.write('<scr' + 'ipt type="text/javascript" src="MathJax/MathJax.js?config=default"></scr' + 'ipt>');})();
</script><!--[if IE 6]><style type="text/css">.SIEHidden { overflow: hidden; }</style><![endif]--></head><body id="scribble-racket-lang-org"><div class="tocset"><div class="tocview"><div class="tocviewlist tocviewlisttopspace"><div class="tocviewtitle"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_0&quot;);">&#9660;</a></td><td></td><td><a href="index.html" class="tocviewlink" data-pltdoc="x">Computational Modeling for Psychology</a></td></tr></table></div><div class="tocviewsublisttop" style="display: block;" id="tocview_0"><table cellspacing="0" cellpadding="0"><tr><td align="right">1&nbsp;</td><td><a href="Introductory_Material.html" class="tocviewlink" data-pltdoc="x">Introduction and Computing Requirements</a></td></tr><tr><td align="right">2&nbsp;</td><td><a href="Computation_and_Cognition.html" class="tocviewlink" data-pltdoc="x">What is Computation and is Cognition Computable?</a></td></tr><tr><td align="right">3&nbsp;</td><td><a href="DEs_and_Spikes.html" class="tocviewlink" data-pltdoc="x">Differential Equations and Spiking Neuron Models</a></td></tr><tr><td align="right">4&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">Neural Networks</a></td></tr><tr><td align="right">5&nbsp;</td><td><a href="Projects.html" class="tocviewlink" data-pltdoc="x">Topics for Final Projects</a></td></tr></table></div></div><div class="tocviewlist"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_1&quot;);">&#9658;</a></td><td>4&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">Neural Networks</a></td></tr></table><div class="tocviewsublistbottom" style="display: none;" id="tocview_1"><table cellspacing="0" cellpadding="0"><tr><td align="right">4.1&nbsp;</td><td><a href="#%28part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks%29" class="tocviewlink" data-pltdoc="x">Introduction to Linear Algebra and Neural Networks</a></td></tr><tr><td align="right">4.2&nbsp;</td><td><a href="#%28part._.The_.Math_.That_.Underlies_.Neural_.Networks_%29" class="tocviewlink" data-pltdoc="x">The Math That Underlies Neural Networks?</a></td></tr><tr><td align="right">4.3&nbsp;</td><td><a href="#%28part._.Perceptrons%29" class="tocviewlink" data-pltdoc="x">Perceptrons</a></td></tr><tr><td align="right">4.4&nbsp;</td><td><a href="#%28part._.Hopfield_.Networks%29" class="tocviewlink" data-pltdoc="x">Hopfield Networks</a></td></tr><tr><td align="right">4.5&nbsp;</td><td><a href="#%28part._.Backpropagation%29" class="tocviewlink" data-pltdoc="x">Backpropagation</a></td></tr></table></div></div></div><div class="tocsub"><div class="tocsubtitle">On this page:</div><table class="tocsublist" cellspacing="0"><tr><td><span class="tocsublinknumber">4.1<tt>&nbsp;</tt></span><a href="#%28part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks%29" class="tocsubseclink" data-pltdoc="x">Introduction to Linear Algebra and Neural Networks</a></td></tr><tr><td><span class="tocsublinknumber">4.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Linear_.Algebra_.Goals%29" class="tocsubseclink" data-pltdoc="x">Linear Algebra Goals</a></td></tr><tr><td><span class="tocsublinknumber">4.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Drawing_.Cellular_.Automata%29" class="tocsubseclink" data-pltdoc="x">Drawing Cellular Automata</a></td></tr><tr><td><span class="tocsublinknumber">4.1.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Comments_on_the_programmatic_implementation%29" class="tocsubseclink" data-pltdoc="x">Comments on the programmatic implementation</a></td></tr><tr><td><span class="tocsublinknumber">4.1.3<tt>&nbsp;</tt></span><a href="#%28part._.More_.Lessons_from_.Cellular_.Automata%29" class="tocsubseclink" data-pltdoc="x">More Lessons from Cellular Automata</a></td></tr><tr><td><span class="tocsublinknumber">4.2<tt>&nbsp;</tt></span><a href="#%28part._.The_.Math_.That_.Underlies_.Neural_.Networks_%29" class="tocsubseclink" data-pltdoc="x">The Math That Underlies Neural Networks?</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Linear_.Algebra%29" class="tocsubseclink" data-pltdoc="x">Linear Algebra</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Important_.Objects_and_.Operations%29" class="tocsubseclink" data-pltdoc="x">Important Objects and Operations</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Adding_.Matrices%29" class="tocsubseclink" data-pltdoc="x">Adding Matrices</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Activity%29" class="tocsubseclink" data-pltdoc="x">Activity</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Common_.Notational_.Conventions_for_.Vectors_and_.Matrices%29" class="tocsubseclink" data-pltdoc="x">Common Notational Conventions for Vectors and Matrices</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2<tt>&nbsp;</tt></span><a href="#%28part._.What_is_a_.Neural_.Network_%29" class="tocsubseclink" data-pltdoc="x">What is a Neural Network?</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Non-linearities%29" class="tocsubseclink" data-pltdoc="x">Non-<wbr></wbr>linearities</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Exercise_.X.O.R%29" class="tocsubseclink" data-pltdoc="x">Exercise XOR</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.2<tt>&nbsp;</tt></span><a href="#%28part._.Connections%29" class="tocsubseclink" data-pltdoc="x">Connections</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.3<tt>&nbsp;</tt></span><a href="#%28part._.Boolean_.Logic%29" class="tocsubseclink" data-pltdoc="x">Boolean Logic</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.4<tt>&nbsp;</tt></span><a href="#%28part.__.First_.Order_.Logic_-_.Truth_.Tables%29" class="tocsubseclink" data-pltdoc="x"> First Order Logic -<wbr></wbr> Truth Tables</a></td></tr><tr><td><span class="tocsublinknumber">4.3<tt>&nbsp;</tt></span><a href="#%28part._.Perceptrons%29" class="tocsubseclink" data-pltdoc="x">Perceptrons</a></td></tr><tr><td><span class="tocsublinknumber">4.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Goals%29" class="tocsubseclink" data-pltdoc="x">Goals</a></td></tr><tr><td><span class="tocsublinknumber">4.3.2<tt>&nbsp;</tt></span><a href="#%28part._.Perceptron_.History_and_.Implementation%29" class="tocsubseclink" data-pltdoc="x">Perceptron History and Implementation</a></td></tr><tr><td><span class="tocsublinknumber">4.3.3<tt>&nbsp;</tt></span><a href="#%28part._.The_.Perceptron_.Rules%29" class="tocsubseclink" data-pltdoc="x">The Perceptron Rules</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4<tt>&nbsp;</tt></span><a href="#%28part._.You_.Are_.The_.Perceptron%29" class="tocsubseclink" data-pltdoc="x">You Are The Perceptron</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.1<tt>&nbsp;</tt></span><a href="#%28part._.A_simple_data_set%29" class="tocsubseclink" data-pltdoc="x">A simple data set</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.2<tt>&nbsp;</tt></span><a href="#%28part._.What_does_it_all_mean__.How_is_the_.Perceptron_.Learning_%29" class="tocsubseclink" data-pltdoc="x">What does it all mean? How is the Perceptron Learning?</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.3<tt>&nbsp;</tt></span><a href="#%28part._.Bias%29" class="tocsubseclink" data-pltdoc="x">Bias</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Geometrical_.Thinking%29" class="tocsubseclink" data-pltdoc="x">Geometrical Thinking</a></td></tr><tr><td><span class="tocsublinknumber">4.3.5<tt>&nbsp;</tt></span><a href="#%28part._.The_.Delta_.Rule_-_.Homework%29" class="tocsubseclink" data-pltdoc="x">The Delta Rule -<wbr></wbr> Homework</a></td></tr><tr><td><span class="tocsublinknumber"></span><a href="#%28part._ref~3aperceptron%29" class="tocsubseclink" data-pltdoc="x">Perceptron Bibliography</a></td></tr><tr><td><span class="tocsublinknumber">4.4<tt>&nbsp;</tt></span><a href="#%28part._.Hopfield_.Networks%29" class="tocsubseclink" data-pltdoc="x">Hopfield Networks</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1<tt>&nbsp;</tt></span><a href="#%28part._.Not_all_.Networks_are_the_.Same%29" class="tocsubseclink" data-pltdoc="x">Not all Networks are the Same</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.1<tt>&nbsp;</tt></span><a href="#%28part._.How_does_a_network_like_this_work_%29" class="tocsubseclink" data-pltdoc="x">How does a network like this work?</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Test_your_understanding_%29" class="tocsubseclink" data-pltdoc="x">Test your understanding:</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.3<tt>&nbsp;</tt></span><a href="#%28part._.A_.Worked_.Example%29" class="tocsubseclink" data-pltdoc="x">A Worked Example</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Distance_.Metrics%29" class="tocsubseclink" data-pltdoc="x">Distance Metrics</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.4<tt>&nbsp;</tt></span><a href="#%28part._.Hebb_s_.Outer_.Product_.Rule%29" class="tocsubseclink" data-pltdoc="x">Hebb&rsquo;s Outer Product Rule</a></td></tr><tr><td><span class="tocsublinknumber">4.4.2<tt>&nbsp;</tt></span><a href="#%28part._.Hopfield_.Homework_.Description__.Robustness_to_.Noise%29" class="tocsubseclink" data-pltdoc="x">Hopfield Homework Description:<span class="mywbr"> &nbsp;</span> Robustness to Noise</a></td></tr><tr><td><span class="tocsublinknumber"></span><a href="#%28part._ref~3ahopfield%29" class="tocsubseclink" data-pltdoc="x">Hopfield Bibliography</a></td></tr><tr><td><span class="tocsublinknumber">4.5<tt>&nbsp;</tt></span><a href="#%28part._.Backpropagation%29" class="tocsubseclink" data-pltdoc="x">Backpropagation</a></td></tr><tr><td><span class="tocsublinknumber">4.5.1<tt>&nbsp;</tt></span><a href="#%28part._.Warm_up_questions%29" class="tocsubseclink" data-pltdoc="x">Warm up questions</a></td></tr><tr><td><span class="tocsublinknumber">4.5.2<tt>&nbsp;</tt></span><a href="#%28part._.Sigmoid_.Functions%29" class="tocsubseclink" data-pltdoc="x">Sigmoid Functions</a></td></tr><tr><td><span class="tocsublinknumber">4.5.2.1<tt>&nbsp;</tt></span><a href="#%28part._.A_few_questions_about_sigmoid_functions%29" class="tocsubseclink" data-pltdoc="x">A few questions about sigmoid functions</a></td></tr><tr><td><span class="tocsublinknumber">4.5.2.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Mean_.Squared_.Error%29" class="tocsubseclink" data-pltdoc="x">Mean Squared Error</a></td></tr><tr><td><span class="tocsublinknumber">4.5.3<tt>&nbsp;</tt></span><a href="#%28part._.Backpropagation_1%29" class="tocsubseclink" data-pltdoc="x">Backpropagation 1</a></td></tr><tr><td><span class="tocsublinknumber">4.5.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Some_.Details%29" class="tocsubseclink" data-pltdoc="x">Some Details</a></td></tr><tr><td><span class="tocsublinknumber">4.5.3.2<tt>&nbsp;</tt></span><a href="#%28part._.Learning_.About_.Backpropagation%29" class="tocsubseclink" data-pltdoc="x">Learning About Backpropagation</a></td></tr><tr><td><span class="tocsublinknumber">4.5.3.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Bread_.Crumbs%29" class="tocsubseclink" data-pltdoc="x">Bread Crumbs</a></td></tr><tr><td><span class="tocsublinknumber">4.5.4<tt>&nbsp;</tt></span><a href="#%28part._.Homework%29" class="tocsubseclink" data-pltdoc="x">Homework</a></td></tr><tr><td><span class="tocsublinknumber">4.5.4.1<tt>&nbsp;</tt></span><a href="#%28part._.Additional_.Readings%29" class="tocsubseclink" data-pltdoc="x">Additional Readings</a></td></tr><tr><td><span class="tocsublinknumber"></span><a href="#%28part._ref~3abackprop%29" class="tocsubseclink" data-pltdoc="x">Backpropagation Bibliography</a></td></tr></table></div></div><div class="maincolumn"><div class="main"><div class="navsettop"><span class="navleft"><div class="nosearchform"></div>&nbsp;&nbsp;<span class="tocsettoggle">&nbsp;&nbsp;<a href="javascript:void(0);" title="show/hide table of contents" onclick="TocsetToggle();">contents</a></span></span><span class="navright">&nbsp;&nbsp;<a href="DEs_and_Spikes.html" title="backward to &quot;3 Differential Equations and Spiking Neuron Models&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="index.html" title="up to &quot;Computational Modeling for Psychology&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Projects.html" title="forward to &quot;5 Topics for Final Projects&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div><h3>4<tt>&nbsp;</tt><a name="(part._.Neural._.Networks)"></a>Neural Networks</h3><h4>4.1<tt>&nbsp;</tt><a name="(part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks)"></a>Introduction to Linear Algebra and Neural Networks</h4><h5>4.1.1<tt>&nbsp;</tt><a name="(part._.Linear_.Algebra_.Goals)"></a>Linear Algebra Goals</h5><p><div class="SIntrapara">Our goal for the next few lessons is to come to understand
</div><div class="SIntrapara"><ul><li><p>What is a neural network?</p></li><li><p>What mathematics are needed to build a neural network?</p></li><li><p>How can neural networks help us understand cognition?</p></li></ul></div></p><p>As a first illustration of some of the key ideas we will execute a simple cellular automata rule. What I hope to emphasize through this exercise is that whenever you can get the computer to do a repetitive task do so. It will do it much better than you. And even if it takes you days to get the program right for many task you will quickly save the time in the long run. Second, we are using a simple rule (as you will shortly see). But even though the rule is local it yields impressive global structure. And very slight tweaks in this local rule can lead to large macroscopic changes. While the variation in our rule is very limited the array of behaviors we can observe is vast. <span class="refelem"><span class="refcolumn"><span class="refcontent">Match these features to facts about neurons. Extend them to what you believe will be their application in neural networks.</span></span></span></p><h5>4.1.2<tt>&nbsp;</tt><a name="(part._.Drawing_.Cellular_.Automata)"></a>Drawing Cellular Automata</h5><p>This activity has several stages. For the first stage make sure you can load the file <a href="&quot;./../code/ca.rkt&quot;"></a> into Dr Racket and that it runs.</p><p>Next, pick a number between 0 and 255 inclusive. In your interactive window use the function <span class="stt">rule-tester</span> to generate the input-output pairing for your rule like so.</p><p><div class="SIntrapara">Testing Rule 22</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">rule-tester</span><span class="hspace">&nbsp;</span><span class="RktVal">22</span><span class="hspace">&nbsp;</span><span class="RktSym">test-set</span><span class="RktPn">)</span></td></tr><tr><td><table cellspacing="0" cellpadding="0"><tr><td><p><span class="RktOut">in (w w w) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (w w b) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (w b w) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (w b b) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b w w) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (b w b) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b b w) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b b b) out w</span></p></td></tr></table></td></tr></table></blockquote></div></p><p>Use your rule and a piece of graph paper to implement your rule.</p><p>Color a single black square in the middle of the top row. Then moving down one row and working left to right implement your rule by coloring in the appropriate square.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="grid.png" alt="" width="359" height="240"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3agrid-automata))" x-target-lift="Figure"></a>Figure&nbsp;5: </span>Nearest Neighbors in the Grid</span></p></blockquote><p>For example, if the boxes 1, 2, and 3 were &rsquo;w, &rsquo;w, and &rsquo;b I could color the square with the question mark black. Then I would move one to the right and square 2 would become my new number 1 and so on.</p><p>Complete several rows following your rule.</p><p>What you have probably noticed is that this is tedious and mistake prone, but your rule is a good example of a function. A function can be conceived as a set of pairs. The first element of the pair is the input, and the second element of the pair is the output. Functions require that each input element be unique. Implementing your rule  makes you the metaphorical neuron deciding whether or not to fire (color the square black) based on the input you receive from neighboring neurons.</p><p>Having learned how tedious and error prone this process explore some of the other rules using the functions in <span class="stt">ca.rkt</span>. The simplest method is to use the function <span class="stt">d-r-a &lt;some-rule-number&gt;</span>. You can adjust the size and scale with various optional arguments and even print it to a file if you find one you like. Here is one of my favorites as a demonstration.</p><p><div class="SIntrapara">Rule 110</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">d-r-a</span><span class="hspace">&nbsp;</span><span class="RktVal">110</span><span class="hspace">&nbsp;</span><span class="RktPn">#:num-rows</span><span class="hspace">&nbsp;</span><span class="RktVal">100</span><span class="hspace">&nbsp;</span><span class="RktPn">#:num-cols</span><span class="hspace">&nbsp;</span><span class="RktVal">100</span><span class="hspace">&nbsp;</span><span class="RktPn">#:scale</span><span class="hspace">&nbsp;</span><span class="RktVal">3</span><span class="RktPn">)</span></td></tr><tr><td><p><img src="pict_8.png" alt="image" width="300" height="303"/></p></td></tr></table></blockquote></div></p><p><div class="SIntrapara">What are the lessons learned from this exercise?
</div><div class="SIntrapara"><ol><li><p>Repetitive actions are hard. We (humans) make mistakes following even simple rules for a large number of repeated steps. Better to let the computer do it since that is where its strengths lie.</p></li><li><p>Complex global patterns can emerge from local actions. Each neuron is only responding to its immediate right and left yet global structures emerge.</p></li><li><p>These characteristics seem similar to brain activity. Each neuron in the brain is just one of many. Whether a neuron spikes or not is a consequence of its own state and its inputs (like the neighbors in the grid example).</p></li><li><p>From each neuron making a local computation, global patterns of complex activity can emerge.</p></li><li><p>Maybe by programming something similar to this system we can get insights into brain activity.</p></li></ol></div></p><h5>4.1.2.1<tt>&nbsp;</tt><a name="(part._.Comments_on_the_programmatic_implementation)"></a>Comments on the programmatic implementation</h5><p>The code in <span class="stt">ca.rkt</span> involves a lot of looping. I used <span style="font-style: italic">for</span> loops extensively, though sometimes these were <span class="stt">for/fold</span> variants. We need to inch along the columns and down the rows. The plotting used the built in functionality of <span style="font-weight: bold">racket</span> for generating pictures as output.</p><p>The potentially more tricky part was going from a number (in decimal) to a binary representation that had the right number of places occupied. I ended going back and forth between strings and lists to get what I wanted. This was undoubtedly a kludge, but there is a slogan to first get it working, and then make it better. Trying to be too perfect and too elegant can cost you time in the long run. It is often easier to revise a functioning program then write one from the start.</p><p>Initially I did not have all the testing code, because I was adapting code I had written in the past. However, when things did not work it turned out I went faster by slowing down and writing code that allowed me to inspect the state of my various variables, and individually try out the small functions on test input.</p><h5>4.1.3<tt>&nbsp;</tt><a name="(part._.More_.Lessons_from_.Cellular_.Automata)"></a>More Lessons from Cellular Automata</h5><p>Cellular automata demonstrate some basic lessons that we will make use of when thinking about neural networks. One of these points is that there may be simple representations for complex entities. If we can find the right language for representation we may get concision and repeatability as by-products. This is demonstrated by the <a href="https://plato.stanford.edu/entries/cellular-automata/supplement.html">naming convention for the rules of cellular automata</a>.</p><p>In emphasizing that local decisions can produce interesting global effects it may be interesting to examine other similar uses of the cellular automata idea. One famous and visually pleasing one is the <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Game of Life</a>.</p><p>The analogy of automata to simple neurons may be deeper than at first it appears. Some very famous thinkers connected the two. One of the most brilliant people of all time, John von Neumann, was working on a book about automata and the brain at the time of his death. I have linked to a commentary in case you are interested in reading further see <a href="http://www.ams.org/bull/1958-64-03/S0002-9904-1958-10214-1/S0002-9904-1958-10214-1.pdf">Claude Shannon (pdf)</a> as well as to a pdf <a href="https://complexityexplorer.s3.amazonaws.com/supplemental_materials/5.6+Artificial+Life/The+Computer+and+The+Brain_text.pdf">copy</a> of the book: <a href="https://ocul-wtl.primo.exlibrisgroup.com/permalink/01OCUL_WTL/vk29fk/alma994863683505162">The Computer and the Brain</a>).</p><p>A contemporary mathematician and the inventor of the Mathematica software system also believes that cellular automata may be a theory of everything. See what Stephen Wolfram <a href="http://www.wolframscience.com">thinks</a>.</p><h4>4.2<tt>&nbsp;</tt><a name="(part._.The_.Math_.That_.Underlies_.Neural_.Networks_)"></a>The Math That Underlies Neural Networks?</h4><h5>4.2.1<tt>&nbsp;</tt><a name="(part._.Linear_.Algebra)"></a>Linear Algebra</h5><p>The math at the heart of neural networks and their computer implementation is <span style="font-style: italic"><span style="font-weight: bold">linear algebra</span></span>. For us, the section of linear algebra we are going to need is mostly limited to vectors, matrices and how to add and multiply them.</p><h5>4.2.1.1<tt>&nbsp;</tt><a name="(part._.Important_.Objects_and_.Operations)"></a>Important Objects and Operations</h5><ol><li><p>Vectors</p></li><li><p>Matrices</p></li><li><p>Scalars</p></li><li><p>Addition</p></li><li><p>Multiplication (scalar and matrix)</p></li><li><p>Transposition</p></li><li><p>Inverse</p></li></ol><h5>4.2.1.1.1<tt>&nbsp;</tt><a name="(part._.Adding_.Matrices)"></a>Adding Matrices</h5><p>To gain some hands on familiarity with the manipulation of matrices and vectors we will try to do some hand and programming exercises for some of the fundamental operations of addition and multiplication. We will also thereby learn that some of the rules we learned for numbers (such as a * b = b * a) do not always apply in other mathematical realms.</p><p>There are in fact many ways to think about what a vector is.</p><p>It can be thought of as a column (or row of numbers).
More abstractly it is an object (arrow) with magnitude and direction.
Most abstractly it is anything that obeys the requirements of a vector space.</p><p>For particular circumstances one or another of the different definitions may serve our purposes better. In application to neural networks we often just use the first definition, a column of numbers, but the second can be more helpful for developing our geometric intuitions about what various learning rules are doing and how they do it.</p><p>Similarly, we often just consider a matrix as a collection of vectors or as a rectangular (2-D) collection of numbers.</p><h5>4.2.1.1.2<tt>&nbsp;</tt><a name="(part._.Activity)"></a>Activity</h5><p>Look up how racket handles <a href="https://docs.racket-lang.org/math/matrices.html">matrices and vectors</a>. Here is a very simple <a href="./../code/la-demo.rkt">file</a> to try and get started.</p><p><span style="font-weight: bold">Important</span>: vectors are a special datatype in Racket, and the vector type is probably not what you want to be using. Look for matrices and linear algebra.</p><p>Make two arrays and make them the same size<span class="refelem"><span class="refcolumn"><span class="refcontent">What is the <span style="font-style: italic">size</span> of a matrix?</span></span></span>.</p><p>Add them together in both orders (A + B and B + A). How does one add an array that itself has numerous different numbers?</p><p>Then do the same for multiplication. Note that there are particular requirements for the sizes of matrices in order that it is possible to multiply them in both directions. What is that rule?</p><p>What is the name for the property of having A*B = B*A?</p><h5>4.2.1.2<tt>&nbsp;</tt><a name="(part._.Common_.Notational_.Conventions_for_.Vectors_and_.Matrices)"></a>Common Notational Conventions for Vectors and Matrices</h5><p>Vectors tend to be notated as <span style="font-style: italic">lower case</span> letters, often in bold, such
as <span class="math">\mathbf{a}</span>. They are also occasionally represented with little
arrows on top such as <span class="math">\overrightarrow{\textbf{a}}</span>.</p><p>Matrices tend to be notated as <span style="font-style: italic">upper case</span> letters, typically in bold,
such as <span class="math">\mathbf{M}</span>.</p><p>Good things to know: what is an <span style="font-style: italic">inner product</span>? How do you compute it in racket?</p><h5>4.2.2<tt>&nbsp;</tt><a name="(part._.What_is_a_.Neural_.Network_)"></a>What is a Neural Network?</h5><p>What is a Neural Network? It is a brain inspired computational approach
in which "neurons" compute functions of their inputs and pass on a
<span style="font-style: italic">weighted</span> proportion to the next neuron in the chain.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="nn.png" alt="" width="400" height="136"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig-nn))" x-target-lift="Figure"></a>Figure&nbsp;6: </span>simple schematic of the basics of a neural network. This is an image for a single neuron. The input has three elements and each of these connects to the same neuron ("node 1"). The activity at those nodes is filtered by the weights, which are specific for each of the inputs. These three processed inputs are combined to generate the output from this neuron. For multiple layers this output becomes an input for the next neuron along the chain.</span></p></blockquote><h5>4.2.2.1<tt>&nbsp;</tt><a name="(part._.Non-linearities)"></a>Non-linearities</h5><p>The spiking of a biological neuron is non-linear. You saw this in both the integrate and fire and Hodgkin and Huxley models you programmed. The lines on those plots you created are not, for the most part, straight. Perhaps the simplest way to incorporate a non-linearity into our artificial neuron is to give it a threshold, like we did for the integrate and fire model. When activity exceeds the threshold (which we will usually designate with a capital Greek Theta <span class="math">\Theta</span> then the neuron is set to 1 and if it is not firing it is set to 0 (like the "w" &#8594; 0; "b" &#8594; 1 mapping we used for the cellular automata).</p><p><div class="math">\begin{equation}
\mbox{if } I_1 \times w_{1,1} + I_2 \times w_{2,1} + I_3 \times w_{3,1} &gt; \Theta \mbox{ then } Output = 1
\end{equation}</div></p><p>What this equation shows is that Inputs (the <span class="math">I</span>s) are passed to a neuron. Those inputs have something like a synapse. That is designated by the w&rsquo;s. Those weights are how tightly the input and internal activity of our artificial neuron is coupled. The reason for all the subscripts is to try and help you see the similarity between this equation and the inner product and matrix multiplication rules you just worked on programming. The activity of the neuron is a sort of internal state, and then, based on the comparison of that activity to the threshold, you can envision the neuron spiking or not, meaning it has value 1 or 0. Mathematically, the weighted sum is fed into a threshold function that compares the value to a threshold <span class="math">\Theta</span>, and passes on the value 1 if it is greater than the threshold and 0 (sometimes <span class="math">-1</span> rather than zero is chosen for the inactive state because there are certain computational conveniences in doing so).</p><p>To prepare you for the next steps in writing a simple percetron (the earliest form of artificial neural network), you should try to answer the followign questons.</p><p><div class="SIntrapara">Questions:
</div><div class="SIntrapara"><ol><li><p>What, geometrically speaking, is a plane?</p></li><li><p>What is a hyperplane?</p></li><li><p>What is linearly separability and how does that relate to planes and
hyperplanes?</p></li></ol></div></p><p>One of our first efforts will be to code a <span style="font-style: italic">perceptron</span> to solve the XOR problem. In order for this to happen you need to know a bit about <span style="font-style: italic">Boolean</span> functions and what an XOR problem actually is.</p><p><span style="font-weight: bold">Examples of Boolean Functions and How They Map onto our Neural Network Intuitions</span></p><p>The "AND" Operation/Function</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_9.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3aand))" x-target-lift="Figure"></a>Figure&nbsp;7: </span>The <span style="font-style: italic">and</span> operation is true when both its inputs are true.</span></p></blockquote><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_10.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3aor))" x-target-lift="Figure"></a>Figure&nbsp;8: </span>The <span style="font-style: italic">or</span> operation is true if either or both of its inputs are true.</span></p></blockquote><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_11.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3axor))" x-target-lift="Figure"></a>Figure&nbsp;9: </span>The <span style="font-style: italic">xor</span> is true when one or the other, but not both of the inputs are true. It is exclusively an or function.</span></p></blockquote><p>This short <a href="https://media.nature.com/m685/nature-assets/nbt/journal/v26/n2/images/nbt1386-F1.gif">article</a> provides a nice example of linear separability and some basics of what a neural network is.</p><h5>4.2.2.1.1<tt>&nbsp;</tt><a name="(part._.Exercise_.X.O.R)"></a>Exercise XOR</h5><p>Using only <span style="font-style: italic">not</span>, <span style="font-style: italic">and</span>, and <span style="font-style: italic">or</span> operations draw the diagram that allows you to compute in two steps the <span style="font-style: italic">xor</span> operation. You will need this to code it up as a perceptron.</p><h5>4.2.2.2<tt>&nbsp;</tt><a name="(part._.Connections)"></a>Connections</h5><p>Can neural networks encode logic? Is the processing zeros and ones enough to capture the richness of human intellectual activity?</p><p>There is a long tradition of representing human thought as the consequence of some sort of calculation of two values (true or false). If you have two values you can swap out 1&rsquo;s and 0&rsquo;s for the true and false in your calculation. They even seem to obey similar laws. If you the conjunction (AND) of two true things it is only true when both are true. If you take T = 1, then T &#8743; T is the same as <span class="math">1~\times~1</span>.</p><p>We will next build up a simple threshold neural unit and try to calculate some of these truth functions with our neuron. We will build simple neurons for truth tables (like those that follow), and string them together into an argument. Then we can feed values of T and F into our network and let it calculate the XOR problem.</p><h5>4.2.2.3<tt>&nbsp;</tt><a name="(part._.Boolean_.Logic)"></a>Boolean Logic</h5><p>George Boole, Author of the <span style="font-style: italic">Laws of Thought</span></p><ul><li><p>Read the <a href="https://archive.org/details/investigationofl00boolrich">book</a> on Archive.org</p></li><li><p>Read about <a href="https://plato.stanford.edu/entries/boole/#LifWor">George Boole</a></p></li></ul><h5>4.2.2.4<tt>&nbsp;</tt><a name="(part.__.First_.Order_.Logic_-_.Truth_.Tables)"></a> First Order Logic - Truth Tables</h5><p><span style="font-weight: bold">Or</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Or</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr></table></p><p><span style="font-weight: bold">And</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">AND</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr></table></p><p><span style="font-weight: bold">Nand</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">NAND</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr></table></p><h4>4.3<tt>&nbsp;</tt><a name="(part._.Perceptrons)"></a>Perceptrons</h4><h5>4.3.1<tt>&nbsp;</tt><a name="(part._.Goals)"></a>Goals</h5><p>The goal for this file is to share the idea of a perceptron, the mathematical formula for updating one, and iniate the process of coding a simple implementation that we will adapt to the delta rule.</p><h5>4.3.2<tt>&nbsp;</tt><a name="(part._.Perceptron_.History_and_.Implementation)"></a>Perceptron History and Implementation</h5><p>The perceptron was the invention of a psychologist, <a href="http://dspace.library.cornell.edu/bitstream/1813/18965/2/Rosenblatt_Frank_1971.pdf">Frank Rosenblatt</a>.  He was not a computer scientist. Though he obviously had a bit of the mathematician in him.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="Mark_I_perceptron.jpeg" alt=""/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3amark.I))" x-target-lift="Figure"></a>Figure&nbsp;10: </span>The Perceptron Mark I</span></p></blockquote><p>Details to be found on the <a href="https://en.wikipedia.org/wiki/Perceptron">wikipedia page</a>.</p><p>Those interested in some interesting background reading could consult his over 600 page book entitled <a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015039846566&amp;view=1up&amp;seq=9">Principles of Neurodynamics</a> or this <a href="https://link.springer.com/book/10.1007/978-3-642-70911-1">historical review</a>.</p><p>From the foreward of that book we have the following quote:</p><p>"For this writer, the perceptron program is not primarily concerned with the invention of devices for "artificial intelligence", but rather with investigating the physical structures and neurodynamic principles which under lie "natural intelligence". A perceptron is first and fore most a brain model, not an invention for pattern recognition. As a brain model, its utility is in enabling us to determine the physical conditions for the emergence of various psychological properties."</p><h5>4.3.3<tt>&nbsp;</tt><a name="(part._.The_.Perceptron_.Rules)"></a>The Perceptron Rules</h5><p>The perceptron rules are the equations that characterize what a perceptron is, and what it does in contact with experience, so that it can learn and revise its behavior. A lot can be done with these simple equations.</p><p><span class="math">I = \sum_{i=1}^{n} w_i~x_i</span></p><p>If <span class="math">I \ge T</span> then <span class="math">y = +1</span> else if <span class="math">I &lt; T</span> then <span class="math">y = -1</span></p><p>If the answer was correct, then <span class="math">\beta = +1</span>, else if the
answer was incorrect then <span class="math">\beta = -1</span>.</p><p>The "T" in the above equation refers to the threshold. This is a user defined value that is conveniently, and often made, to be zero.</p><p>Updating is done by <span class="math">\mathbf{w_{new}} =
\mathbf{w_{old}} + \beta y \mathbf{x}</span></p><h5>4.3.4<tt>&nbsp;</tt><a name="(part._.You_.Are_.The_.Perceptron)"></a>You Are The Perceptron</h5><p>This is a pencil and paper exercise. Before coding it is often a good idea to try and work the basics out by hand. This may be a flow chart or a simple hand worked example. This both gives you a simple test case to compare your code against, but more importantly makes sure that you understand what you are trying to code. Let&rsquo;s make sure you understand how to compute the perceptron learning rule, but doing a simple case by hand.</p><p>Beginning with an input of <span class="math">\begin{bmatrix}0.3 \\ 0.7 \end{bmatrix}</span>, an initial set of weights of <span class="math">\begin{bmatrix}-0.6 \\ 0.8 \end{bmatrix}</span>, and a <span style="font-weight: bold">class</span> of 1. Compute the value of the new weight vector with pen and paper.</p><h5>4.3.4.1<tt>&nbsp;</tt><a name="(part._.A_simple_data_set)"></a>A simple data set</h5><p>For these data there are two dimensions or features (the first and second columns) and the third colum represents their <span style="font-style: italic">class</span>.</p><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="RktPn">(</span><span class="RktSym">matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktPn">[</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal">0.7</span><span class="hspace">&nbsp;</span><span class="RktVal">1.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.5</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal">0.7</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal">1.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.2</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-0</span>.8</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr></table></blockquote><p>Using the starting weight above write code to iteratively compute a new weight from each input and it&rsquo;s class and using the current weight. If you can, save each updated weight so you can see how they change, but if you can&rsquo;t still try to use a for construct to iterate through these data and see how the weights change.</p><p>In broad outlines you will need to decide on a data structure. You can use a matrix as I have here, but it may be easier to just use a list to start. For example <span class="RktPn">(</span><span class="RktSym">list</span><span class="stt"> </span><span class="RktPn">(</span><span class="RktSym">list</span><span class="stt"> </span><span class="RktVal">0.3</span><span class="stt"> </span><span class="RktVal">0.7</span><span class="RktPn">)</span><span class="stt"> </span><span class="RktVal">1.0</span><span class="RktPn">)</span>. The first element of the list would be the input data and the last item the desired class. You could create a list of list of such elements to capture the matrix I have displayed above.</p><p>This progressive updating of the weight vector is the <span style="font-style: italic">learning</span>. Note that sometimes our initial weight vector classifies incorrectly. How does it do after one complete cycle through all the training examples?</p><p><div class="SIntrapara">Checking our Learned Weight For One Input</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">let</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktPn">[</span><span class="RktSym">in-class</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">if</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">=</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">if</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">&gt;=</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">matrix-ref</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">matrix*</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">row-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.6</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">col-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal">1.2</span><span class="hspace">&nbsp;</span><span class="RktVal">2.3</span><span class="RktPn">]</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">0</span><span class="hspace">&nbsp;</span><span class="RktVal">0</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">0.0</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktVal">1</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span></span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktSym">in-class</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">"correct"</span><span class="hspace">&nbsp;</span><span class="RktVal">"incorrect"</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr></table></td></tr><tr><td><p><span class="RktRes">"correct"</span></p></td></tr></table></blockquote></div></p><h5>4.3.4.2<tt>&nbsp;</tt><a name="(part._.What_does_it_all_mean__.How_is_the_.Perceptron_.Learning_)"></a>What does it all mean? How is the Perceptron Learning?</h5><p><div class="SIntrapara">Changing Weights as Vectors</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="RktPn">(</span><span class="RktSym">wt-plot</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">one-loop-through-data</span><span class="hspace">&nbsp;</span><span class="RktSym">my-data</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">col-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.6</span><span class="hspace">&nbsp;</span><span class="RktVal">0.8</span><span class="RktPn">]</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr><tr><td><p><img src="pict_12.png" alt="image" width="400" height="400"/></p></td></tr></table></blockquote></div></p><p>These functions and the <span class="stt">my-data</span> are in the file <a href="./../code/perceptron-rule.rkt">perceptron-rule.rkt</a>. Each time through the perceptron rule I compute the new weights and use the first position as the &rsquo;x&rsquo; value and the second position as the &rsquo;y&rsquo; value to plot vectors on an &rsquo;x-y&rsquo; plane. You can imagine that as we iterate through the data we are rotating the vectors around an origin. The decision plane is perpendicular to the vectors and anchored at the bottom of the arrows. If you compare this to the location of the data points (which you can add to the plot by editing the functions in the linked file) you will see that the rule is learning to find the decision plane that puts all of one class on one side of the line and all of the other class on the other side. That is why it is limited to problems that are linearly separable!</p><h5>4.3.4.3<tt>&nbsp;</tt><a name="(part._.Bias)"></a>Bias</h5><p>These data were selected such that the base of the vector could separate them while anchored at zero. However, for many data sets you not only need to learn what direction to point the vector, but you also need to learn where to anchor the vector. This is done by including a <span style="font-weight: bold">bias weight</span>. Add an extra dimension to your weight vector and your inputs. For the inputs it will just be a constant value of 1.0, but this extra, bias weight, will also be learned and allows you to achieve, effectively, a translation away from the origin to be able to separate points that are more heterogeneously scattered.</p><h5>4.3.4.3.1<tt>&nbsp;</tt><a name="(part._.Geometrical_.Thinking)"></a>Geometrical Thinking</h5><ul><li><p>What is the relation between the inner product of two vectors and the cosine of the angle between them?</p></li><li><p>What is the *sign* for the cosine of angles less than 90 degrees and those greater than 90 degrees?</p></li><li><p> How do these facts help us to answer the question above?</p></li><li><p> Why does this reinforce the advice to think /geometrically/ when thinking about networks and weight vectors?</p></li></ul><h5>4.3.5<tt>&nbsp;</tt><a name="(part._.The_.Delta_.Rule_-_.Homework)"></a>The Delta Rule - Homework</h5><p>The <span style="font-weight: bold"><span style="font-style: italic">Delta Rule</span></span> is another simple learning rule that is a minimal variation on the perceptron rule. It is used more frequently, and it has the spirit of Hebbian learning, which we will learn more about soon. The homework asks you to write code to test and train an artificial neuron using the delta learning rule.</p><ol><li><p>For an easy start create some pseudo random linearly separable points on a a sheet of paper. Label one population as <span style="font-weight: bold">1</span> and the other population as <span style="font-weight: bold">-1</span>.</p></li><li><p>For a more challenging set-up create the data programatically using random numbers and some method that allows you to vary how close or distant the points are to the line of separation, and how many points there are to train on.</p></li><li><p>The Delta Learning rule is: <div class="math">\Delta~w_i = x_i~\eta(desired - observed)</div></p></li><li><p>Submit your code that has your test data in it. Start with an initial random weight and use the delta rule to learn the correct weighting to solve all your training examples. Then test on a new set of points that you did <span style="font-weight: bold">not</span> test on but that are classified according to the same rule. Your code should assess how well the <span style="font-style: italic">trained</span> rule classifies the <span style="font-style: italic">test</span> data.</p></li></ol><p>I have <a href="./../code/perceptron-rule.rkt">some code</a> for the perceptron that might give you some code you could adapt if you have trouble getting started.</p><h5><a name="(part._ref~3aperceptron)"></a>Perceptron Bibliography</h5><p><table cellspacing="0" cellpadding="0" class="AutoBibliography"><tr><td></td></tr></table></p><h4>4.4<tt>&nbsp;</tt><a name="(part._.Hopfield_.Networks)"></a>Hopfield Networks</h4><h5>4.4.1<tt>&nbsp;</tt><a name="(part._.Not_all_.Networks_are_the_.Same)"></a>Not all Networks are the Same</h5><ul><li><p>Feedforward</p></li><li><p>Recurrent</p></li><li><p>Convolutional</p></li><li><p>Multilevel</p></li><li><p>Supervised</p></li><li><p>Unsupervised</p></li></ul><p>The Hopfield network<span class="Autobibref">&nbsp;(<a href="#%28autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79%2C._pp..._2554--25581982https~3a%2F%2Fwww..pnas..org%2Fdoi%2Fabs%2F10..1073%2Fpnas..79..8..2554%29" class="AutobibLink" data-pltdoc="x">Hopfield</a> <a href="#%28autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79%2C._pp..._2554--25581982https~3a%2F%2Fwww..pnas..org%2Fdoi%2Fabs%2F10..1073%2Fpnas..79..8..2554%29" class="AutobibLink" data-pltdoc="x">1982</a>)</span> has taught many lessons, both practical and conceptual. Hopfield showed physicists a new realm for their skills and added recurrent (i.e. feedback) connections to network design (output becomes input). He changed the focus from network architecture to that of a dynamical system. Hopfield showed that the network could remember and it could do some error correction, it could reconstruct the "right" answer from faulty input.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_13.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3ahopfield-net))" x-target-lift="Figure"></a>Figure&nbsp;11: </span>Hopfield Recurrent Connections</span></p></blockquote><h5>4.4.1.1<tt>&nbsp;</tt><a name="(part._.How_does_a_network_like_this_work_)"></a>How does a network like this work?</h5><ul><li><p>Each node has a value.</p></li><li><p>Each of those arrowheads has an associated weight.</p></li><li><p>The line with the "x" indicates that there are no self connections.</p></li><li><p>All other connections for all other units are present and go in both directions.</p></li></ul><h5>4.4.1.2<tt>&nbsp;</tt><a name="(part._.Test_your_understanding_)"></a>Test your understanding:</h5><ol><li><p>Tell me what the input for a network like this with four nodes should look like it terms of the linear algebra constructs we have talked about.</p></li><li><p>A weight is a number associated to each connection. Tell me what the weights should look like in terms of the linear algebra constructs.</p></li><li><p>How might we conceive of "running" the network for one cycle in terms
of the above.</p></li></ol><h5>4.4.1.3<tt>&nbsp;</tt><a name="(part._.A_.Worked_.Example)"></a>A Worked Example</h5><p>Inputs can be thought of as vectors. Although I have drawn the network like a square that shape is really independent of the structure of data flow. Each node needs an input and each node will need a weighted contact to all the other nodes. Consider the following two input patterns and the following weight matrix.
  <div class="math">A = \{1,0,1,0\}^T</div></p><p><div class="math">B = \{0,1,0,1\}^T</div></p><p><div class="math">weights =  \begin{bmatrix}
  0 &amp; -3 &amp; 3 &amp; -3\\
  -3 &amp; 0 &amp; -3 &amp; 3\\
  3 &amp; -3 &amp; 0 &amp; -3\\
  -3 &amp; 3 &amp; -3 &amp; 0\\
  \end{bmatrix}</div></p><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Ask yourself, how do I compute the output? Which comes first: the matrix or the input vector and why?</p></blockquote></blockquote></blockquote><p>Hopfield networks use a threshold rule. This non-linearity is, at least metaphorically, like the threshold that says whether a neuron in the brain or in our integrate and fire model fires. For the Hopfield network our threshold rule says:</p><p><div class="math">output(t)=\{\begin{array}{c} 1\; \mbox{if } t \geq \Theta\\ 0\; \mbox{if } t &lt; \Theta \end{array}</div></p><p><span class="math">\Theta</span> will represent the value of our threshold and for now let&rsquo;s set <span class="math">\Theta = 0</span>.</p><p>To make sure you understand the mechanics of this type of network you should first calculate the output to each of the two input patterns.</p><p>Then, to test your intuition, you should guess what output you would get for an input of <span class="math">\{1,0,0,0\}^T</span>. Calculate it.</p><p>To understand why this is the case, ask yourself whether A or B is <span style="font-weight: bold">closer</span> to this test input? This will hopefully lead you to reflect on what it means, in this context, for one vector to be "closer" to another.</p><h5>4.4.1.3.1<tt>&nbsp;</tt><a name="(part._.Distance_.Metrics)"></a>Distance Metrics</h5><p>Metrics relate to measurement. For some operation to be a distance metric it should meet three intuitive requirements and one that is maybe not as obvious. To measure the distance between two things we need an operation that is binary. That is, it takes two inputs. In this case that would be our two vectors. It&rsquo;s result should always be <span style="font-weight: bold">Non-negative</span>. A negative distance would clearly be meaningless. Our output should be <span style="font-weight: bold">symmetric</span>. Meaning that <span class="math">d(A,B)~d(B,A)</span>. The distance from Waterloo to Toronto ought to come out as the same as going from Toronto to Waterloo. Our metric should be <span style="font-weight: bold">reflexive</span>. The distance from anything to itself ought to be zero. Lastly, to be a distance metric, our operation must obey the <a href="https://en.wikipedia.org/wiki/Triangle_inequality"><span style="font-weight: bold">triangle inequality</span></a></p><p>Now, to understand what the network did, consider your distance measure to be the number of mismatched bits. This metric is called the Hamming distance.</p><p><span style="font-style: italic">Reminder</span>: Don&rsquo;t forget to think about geometry and dynamics.</p><p>For perceptrons we talked about how the weight vector moved the direction it pointed. Here we don&rsquo;t have the weight vector moving, but you can visualize what is happening as updating a point in space. When we first input our four element vector we have a location in 4-D space. We multiply the first row of our weight matrix against our column of the input vector and we see, in effect, what is the effect on our first element (node) of all the other weighted inputs coming in to it. We then "update" that location. Maybe we flip it from a 1 to a zero (or vice versa). Then we try the next row of the weight matrix to see what happens to the second element. As we change the values of our nodes we are creating new points. The sequence of points is a trajectory that we are tracing in the input space. In this simple situation here we only require one pass to reach the final location, but in other settings we might not. In that case we just keep repeating the process until we do. One of the wonderful insights that Hopfield had was that by conceptualizing this process as an "energy" he could mathematically prove that the process would always reach a resting place.</p><h5>4.4.1.4<tt>&nbsp;</tt><a name="(part._.Hebb_s_.Outer_.Product_.Rule)"></a>Hebb&rsquo;s <a href="https://en.wikipedia.org/wiki/Outer_product">Outer Product</a> Rule</h5><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Why is this learning rule called "Hebb&rsquo;s"? And if you don&rsquo;t know who Hebb is let&rsquo;s take a moment to figure that out.</p></blockquote></blockquote></blockquote><p><div class="SIntrapara">The strength of a change in a connection is proportionate to the product of the input and outputs, i.e. <div class="math">\Delta A[i,j] = \eta f[j]g[i]</div> and <div class="math">g[i] = \sum_j~A[i,j]~f[j]</div> therefore, <div class="math">\vec{g} = \mathbf{Af}</div>. </div><div class="SIntrapara"><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Does it matter that the (\mathbf{W}) comes first?</p></blockquote></blockquote></blockquote></div></p><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>What is an outer product? Can you compute one with racket?</p></blockquote></blockquote></blockquote><h5>4.4.2<tt>&nbsp;</tt><a name="(part._.Hopfield_.Homework_.Description__.Robustness_to_.Noise)"></a>Hopfield Homework Description: Robustness to Noise</h5><p><div class="SIntrapara">Overview of the steps to take:
</div><div class="SIntrapara"><ol><li><p>Create a small set of random data for input patterns.</p></li><li><p>Generate the weights necessary to properly decode the inputs.</p></li><li><p>Conceive of a way to randomly corrupt the inputs. Perhaps by flipping some bits and show that your network does correctly decode the uncorrupted inputs.</p></li><li><p>Report the accuracy of the output. Explore how the length of the input vector and the number of bits your "flip" impact performance.</p></li></ol></div></p><p><div class="SIntrapara">Detailed instructions:
</div><div class="SIntrapara"><ol><li><p>Make the input patterns 2-d, square and of size "n".</p></li><li><p>Use a bipolar system and have, roughly, equal numbers of +1s and -1s in your patterns.</p></li><li><p>Make a few of them and store them in some sort of data structure.</p></li><li><p>Using those patterns, compute the weight matrix with the following equation:
<div class="math">w_{ij} =\frac{1}{N} \sum_{\mu} value^\mu_i \times value^\mu_j</div>
Where N is the size of the patterns, that is how many "neurons". <span class="math">\mu</span> is an index for each of the patterns, and <span class="math">i</span> and <span class="math">j</span> refer to the neurons in the pattern <span class="math">\mu</span>. Do this <span style="font-weight: bold">in code</span>. The computer is good   for this manual, repetitive sort of stuff.</p></li><li><p>Program an <span style="font-weight: bold">asynchronous</span> updating rule, run your network until it stabilizes, and then show that you get back what you put in.</p></li><li><p>Then do the same for at least one disrupted pattern (where you   flipped a couple of bits around.)</p></li></ol></div></p><h5><a name="(part._ref~3ahopfield)"></a>Hopfield Bibliography</h5><p><table cellspacing="0" cellpadding="0" class="AutoBibliography"><tr><td><p><span class="Autobibtarget"><a name="(autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79,._pp..._2554--25581982https~3a//www..pnas..org/doi/abs/10..1073/pnas..79..8..2554)"></a><span class="Autobibentry">J. J. Hopfield. Neural networks and physical systems with emergent collective computational abilities. <span style="font-style: italic">PNAS</span> 79, pp. 2554&ndash;2558, 1982. <a href="https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554"><span class="url">https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554</span></a></span></span></p></td></tr></table></p><h4>4.5<tt>&nbsp;</tt><a name="(part._.Backpropagation)"></a>Backpropagation</h4><h5>4.5.1<tt>&nbsp;</tt><a name="(part._.Warm_up_questions)"></a>Warm up questions</h5><ol><li><p>What is a neural network?</p></li><li><p>What is the difference between supervised and unsupervised learning? Give an example of each?</p></li><li><p>What is the <span style="font-style: italic">activation function</span> we have used for the perceptron and delta rule networks?</p></li><li><p>What role does "error" play in the perceptron and delta learning rules?</p></li><li><p>For a multilayer network how do you know how much of the "error" to pass back into the deeper layers of the network?</p></li></ol><h5>4.5.2<tt>&nbsp;</tt><a name="(part._.Sigmoid_.Functions)"></a>Sigmoid Functions</h5><p>Our prior networks have been forms of threshold units. We check to see if our activation cleared a certain hurdle, and if so, set its value to 1 or -1.</p><p>While this step-function approach was used originally, it is more common now to scale the output continuously between a lower and upper bound. One of the intuitions is that this is like a probability that the neuron might fire.</p><p><div class="SIntrapara">Example:</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">begin</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">define</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">sig</span><span class="hspace">&nbsp;</span><span class="RktSym">x</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">/</span><span class="hspace">&nbsp;</span><span class="RktVal">1.0</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">+</span><span class="hspace">&nbsp;</span><span class="RktVal">1</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">exp</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">*</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="hspace">&nbsp;</span><span class="RktSym">x</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">plot</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">function</span><span class="hspace">&nbsp;</span><span class="RktSym">sig</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym"><span class="nobreak">-</span></span><span class="hspace">&nbsp;</span><span class="RktVal">5</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">5</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">#:title</span><span class="hspace">&nbsp;</span><span class="RktVal">"A sigmoid function."</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr></table></td></tr><tr><td><p><img style="vertical-align: 0px; margin: -3px -3px -3px -3px;" src="pict_14.png" alt="image" width="406" height="406"/></p></td></tr></table></blockquote></div></p><p><span class="math">\frac{1}{1+e^{-z}}</span></p><h5>4.5.2.1<tt>&nbsp;</tt><a name="(part._.A_few_questions_about_sigmoid_functions)"></a>A few questions about sigmoid functions</h5><ol><li><p>Why is it called "sigmoid?"</p></li><li><p>What advantage does it offer over a threshold function?</p></li><li><p>Is it the only "sigmoid" function? Does it have other names?</p></li><li><p>Can you guess an an advantage to this particular form of the equation?</p></li><li><p>How do use this with a neural network, i.e. what is <span class="math">z</span>?</p></li></ol><p>Getting ready to put things together. Can you write a small snippet of racket code that takes a vector of inputs, appends a bias input, combines this with a suitable weight vector using the scalar product and pipes the result though the sigmoid function?
Think about equations qualitatively.</p><p>Remember, one of the goals of computational modeling is to get an insight into the implications of our ideas and theories. Sometimes this means running a model to see what comes out of it. But it can also mean that we look at the equations that go into the model and think about their "behavior" to get some sense of how things will behave that have particular functional forms.</p><p>How might you do that here? Think about how it the process just described is the same as, and different from, the threshold based rules we have been using up until now. Think about extreme values: what happens at the extremes? How is that like (or different from) our older threshold rules?</p><p>Remember that derivatives are rates of change. If we want to know how the error changes as we change something else we will need a derivative. What problem does this approach run into when using a threshold unit?</p><p>In the sigmoid illustrated above where is the derivative maximal? What happens if the dot product of a weight vector and input vector are large? Or very small (and what does small mean here)? What about negative extremes and positive extremes.</p><p>Can you think of a function that would give us an even simpler derivative and why might we want (or not want) to use it?</p><p>Why are we starting this discussion of the backpropagation algorithim with all this discussion of activation functions?</p><p>In summary, we want to understand ...
1. What is being backpropagated?
2. What is it we want our network to do?
3. How do we guide it?</p><p>Many networks have a cost function. We may want to know more than just whether you were right or wrong, but how wrong? In a continuous case being "right" might not even really be possible - what is the value of <span class="math">\pi</span> ? Our computers cannot be precise. There is not a single "right" cost function either, but what might you suggest that we use, and why?</p><p>What would you suggest as the cost function?</p><h5>4.5.2.1.1<tt>&nbsp;</tt><a name="(part._.Mean_.Squared_.Error)"></a>Mean Squared Error</h5><p>It&rsquo;s always a good guess and a resonable starting point</p><p><div class="math">C(\mathbf{w}) = \frac{1}{2\mathrm{n}}\sum_\mathbf{x} \lVert \mathbf{y}(\mathbf{x}) - \mathbf{a}\rVert^2</div></p><p>Some Questions:
Why isn&rsquo;t this a function of <span class="math">\mathbf{x}</span> and <span class="math">\mathbf{y}</span> too?</p><p>What is the <span style="font-style: italic">dimensionality</span> of the part of the equation inside the double lines?</p><p>What do you call the operation characterized by the double lines?</p><p>Why is adjusting weights for a multilayer network hard?</p><h5>4.5.3<tt>&nbsp;</tt><a name="(part._.Backpropagation_1)"></a>Backpropagation 1</h5><p>We learned in implementing the XOR function that we can solve complex (i.e. non-linearly separable ones) problems if we use a <span style="font-style: italic">multi-layer</span> network. However we have a problem. In a single layer network it is clear how our output error depends on the weights, but how do we apportion out the error to earlier layers when we are in a multi-layer situation?</p><p>If you think about it the only thing we are really free to change are the weights. Sure, our error will change if we change the output to make it closer to the input, but in the common scenarios for which we use such neural networks we want to achieve a particular input-output mapping. For that reason as well, we can&rsquo;t alter our inputs. They are our data. We have to accept them as given.</p><p>If weights are the only thing we can change we have to discover, if one exists, an algorithm for apportioning out the error to early weights. This is the achievement of <a href="http://www.nature.com/nature/journal/v323/n6088/pdf/323533a0.pdf">backpropagation algorithm</a>. If you look you will find that you can read this article. It does not use any mathematical concepts that we have not already covered. You have all the notation, language, and concepts. Note that the abstract makes sense to you.</p><p><span style="font-style: italic"><span style="font-weight: bold">Class Question?</span></span>
Is backpropagation biologically plausible?</p><p>Some intuition can help to understand the ideas behind the backpropagation algorithm even if the math gets too intricate for you (and it is more an issues of intricacy than concepts). If we get a wrong answer we might want to change the contributions from a node that is very active. This is because that even if we have a node that is badly weighted if its total activation is small it can&rsquo;t be contributing much to the error. We want to concentrate on nodes and weights were the activity is large and thus small changes will have big effects on errors. This should suggest the idea of a derivative. We want to put most of our change at locations where the ratio of improved output to small changes of weights is high. It is there we get the best return from our adjustment.</p><h5>4.5.3.1<tt>&nbsp;</tt><a name="(part._.Some_.Details)"></a>Some Details</h5><p>The mathematics behind the backpropagation algorithm involves derviatives. These derivatives are usually "partial". We study the rate of change of our dependent variable as a function of one of many possible independent variables. If we want to study how the error changes as we change one specific weight in our network we are looking at the particial derivative. This is typically notated with a sort of curly d like <span class="math">\partial</span>. This means that we could write our rate of change of the error as a function of the change in a particular weight in layer l connecting the kth neuron in the l-1 layer to the jth neuron in the l layer as
<span class="math">\frac{\partial E}{\partial w_{jk}^l}</span>. Note this ordering maybe backwards from your intuition.</p><p>We do not have an equation that directly specifies the change of error in terms of a specific weight, but we can tell how the error changes if we change the output of the last layer. That output is determined by our activation function which is determined in part by the input. By looking how this chain of relationships change we can track our way back to a dependency on the weights. In calculus there is a rule for navigating such chains. It is called the <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>.</p><p>The details of all this back tracking is tedious, but collapses into two different classes. One is for the output layer where we have a direct comparison to the error. The second is all the earlier layers, the so-called "hidden" layers, where we have to say our a current weights change depends on what went before. Thus to know what to do at layer l-1 we need to know facts about layer l. But we only need the immediately preceding layer. So, if we start at the top and work our way back layer by layer we can backpropagate the error. Doing the same thing over and over again is what computers are good at and people are bad, so if we can we want to write a program do this repetitive computation for us.</p><p>Today, there are many nice libraries that have been written to scale nicely, and to run efficiently. We do not have to write this algorithm ourselves. One of the most popular is the python library <a href="https://pytorch.org/">pyTorch</a>. If you plan to use backpropagation for any real application you should probably not write your own implementation. It is an error prone and frustrating process that will probably not run as fast or reliably as the use of an external library. Check your language for a suitable implementation.</p><h5>4.5.3.2<tt>&nbsp;</tt><a name="(part._.Learning_.About_.Backpropagation)"></a>Learning About Backpropagation</h5><p>While the above is true for a professional use case, it is not true from a learning perspective. There are many benefits from working through some of the math yourself, and trying to write your own simple implementation. The following are intended as bread crumbs if you decide to follow that route.</p><h5>4.5.3.2.1<tt>&nbsp;</tt><a name="(part._.Bread_.Crumbs)"></a>Bread Crumbs</h5><p>If you decide to try and follow the chain rule chain to see how weights in early layers can be updated based on backpropagated errors start with a single linear line of nodes that each one connects to the next with a single weight. This is not a useful network for computing anything, but it is a nice simple system for exploring the mathematical relationships without worrying too much about subscripts.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_15.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3alinear-net))" x-target-lift="Figure"></a>Figure&nbsp;12: </span>A simple linear network that can be useful for tracking the chain rule derivations.</span></p></blockquote><p>I found this <a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">this page</a> to give a very nice overview of the derivatives and how they relate as you expand them via the chain rule. There are also some simple numerical examples that you can work by hand to check your understanding. This site does not include code, which can be a nice way to focus on the logic before worrying about how to implement it.</p><p>Often you will see the "sigma" character in on line discussion. This sigma is generally whatever sigmoid, roughly s-shaped, function is being used. As such, the specific derivative will depend on that choice. Don&rsquo;t assume that it is always going to be the logistic function, though this is a common choice.</p><p>How would you write as an equation with the "sigma" (<span class="math">\sigma</span> summation sign the value activation of a single <span style="font-style: italic">arbitrary</span> neuron in an <span style="font-style: italic">arbitrary</span> layer of a multi-layer network?</p><p><span style="font-weight: bold">The activation</span></p><p>To help you check your understanding try to describe in words what is happening here:
<div class="math">a^l_j = \sigma \left ( \sum_k w_{jk}^l~a^{l-1}_k \right )</div></p><p>One of the reasons for this type of equation with all its formatting as subscripts and superscripts is that the coding of the backpropagation algorithm often uses multi-dimensional arrays. All the inputs are treated as vectors and loaded into a matrix where each row (or column) is one pattern, and the collection is a matrix. The weights between one layer and the next are going to be a matrix as well with one dimension the number of nodes in the first layer and the other dimension the number of nodes in the next layer. Each row/column intersetion holds the value of one weight. To collect all the weight matrices into a single structure we need to aggregate them into some sort of three dimensional structure where each matrix can be thought to be stacked on the one that came before. If this sounds complicated to think about imagine trying to code it. It is a project, and it does not map easily on to the logic of the neural network that we learn about as layers and nodes serially connected.</p><p>In addition, there are other arrays that are needed. We must keep track of the errors that we backpropagate and the inputs that are going forward. Depending on your implementation you may need an array for inputs, one for weights, one for activations, one for "deltas", and then you will need to progressively loop over all the layers from beginning to end to get the feedforward output, and then backwards to apply the weight adjustments from end to beginning. This requires careful book-keeping and making sure you orient the various matrices correctly.</p><p>If you are looking for a step by step approach to coding this algorithm, one that uses an object oriented orientation, this <a href="https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/">version</a> in python is accessible.</p><p><div class="SIntrapara">Here is a pseudo-code summary:
</div><div class="SIntrapara"><ol><li><p>Fix the inputs of the first layer to the input pattern <span class="math">x</span></p></li><li><p>Compute the weighted input to each neuron of the next layer using the input, weights and biases.</p></li><li><p>Compute the weighted cost function error vector for the last layer.</p></li><li><p>Backpropagate the error</p></li><li><p>Use the backpropagated error to update the weights</p></li></ol></div></p><p>I wrote a version in racket that seems to work for simple cases. As I only tested it in a few limited cases you are encourged to probe it for bugs and logic errors and suggest corrections.</p><p><div class="SIntrapara">Illustrating Backpropagation Code</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">begin</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">displayln</span><span class="hspace">&nbsp;</span><span class="RktVal">"Before Training"</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">for</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktPn">[</span><span class="RktSym">i</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">map</span><span class="hspace">&nbsp;</span><span class="RktSym">first</span><span class="hspace">&nbsp;</span><span class="RktSym">data-xor</span><span class="RktPn">)</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">displayln</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">test-learning</span><span class="hspace">&nbsp;</span><span class="RktSym">i</span><span class="hspace">&nbsp;</span><span class="RktSym">test-net</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">define</span><span class="hspace">&nbsp;</span><span class="RktSym">many-loops-bp</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">bp-loop</span><span class="hspace">&nbsp;</span><span class="RktSym">data-xor</span><span class="hspace">&nbsp;</span><span class="RktSym">test-net</span><span class="hspace">&nbsp;</span><span class="RktPn">#:loop-no</span><span class="hspace">&nbsp;</span><span class="RktVal">1000</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">displayln</span><span class="hspace">&nbsp;</span><span class="RktVal">"After Training 1000 loops"</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">for</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktPn">[</span><span class="RktSym">i</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">map</span><span class="hspace">&nbsp;</span><span class="RktSym">first</span><span class="hspace">&nbsp;</span><span class="RktSym">data-xor</span><span class="RktPn">)</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">displayln</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">test-learning</span><span class="hspace">&nbsp;</span><span class="RktSym">i</span><span class="hspace">&nbsp;</span><span class="RktSym">many-loops-bp</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr></table></td></tr><tr><td><table cellspacing="0" cellpadding="0"><tr><td><p><span class="RktOut">Before Training</span></p></td></tr><tr><td><p><span class="RktOut">(0.5777916162589202)</span></p></td></tr><tr><td><p><span class="RktOut">(0.5464442087483444)</span></p></td></tr><tr><td><p><span class="RktOut">(0.5684282822675966)</span></p></td></tr><tr><td><p><span class="RktOut">(0.5379860708736727)</span></p></td></tr><tr><td><p><span class="RktOut">After Training 1000 loops</span></p></td></tr><tr><td><p><span class="RktOut">(0.09166884017614642)</span></p></td></tr><tr><td><p><span class="RktOut">(0.902284231676106)</span></p></td></tr><tr><td><p><span class="RktOut">(0.9042320756812994)</span></p></td></tr><tr><td><p><span class="RktOut">(0.11973079775031721)</span></p></td></tr></table></td></tr></table></blockquote></div></p><h5>4.5.4<tt>&nbsp;</tt><a name="(part._.Homework)"></a>Homework</h5><p><div class="SIntrapara">The homework will only require you to use the library provided in order to explore some of the features of the backpropagation algorithm. It will acquaint you with some of the terminology and some of the practical considerations.
</div><div class="SIntrapara"><ol><li><p>Does a backpropagation network always get the same answer? Create at least three random networks. Train them for the same number of trials and compare their accuracy at the end and inspect the weights of the last layer. Are they the same?</p></li><li><p>Does the number of neurons matter or the number of layers? Should you need more than one layer? Compare a 2 - 5 - 5 - 1 to a 2 - 10 - 1 network and report your observations.</p></li><li><p>What is a global minimum and how does it differ from a local minimum. Which are you guaranteed to get with backprop?</p></li><li><p>Test your network for catastrophic forgetting. In my code I train on each of the four XOR inputs one after the other over and over. Test just one pattern for the same number of loops. Then, using those weights as your ending verify you are getting the correct answer. Then train on the second pattern starting from that network. Now go back and test on the original input pattern. Report on your observations.</p></li></ol></div></p><h5>4.5.4.1<tt>&nbsp;</tt><a name="(part._.Additional_.Readings)"></a>Additional Readings</h5><p><div class="SIntrapara">In years past some student have recommend other sources they like.
</div><div class="SIntrapara"><ul><li><p><a href="http://neuralnetworksanddeeplearning.com/chap1.html">On line deep learning textbook</a></p></li><li><p><a href="https://youtu.be/bxe2T-V8XRs?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU">Youtube video on backpropagation coding</a></p></li></ul></div></p><h5><a name="(part._ref~3abackprop)"></a>Backpropagation Bibliography</h5><p><table cellspacing="0" cellpadding="0" class="AutoBibliography"><tr><td></td></tr></table></p><div class="navsetbottom"><span class="navleft"><div class="nosearchform"></div>&nbsp;&nbsp;<span class="tocsettoggle">&nbsp;&nbsp;<a href="javascript:void(0);" title="show/hide table of contents" onclick="TocsetToggle();">contents</a></span></span><span class="navright">&nbsp;&nbsp;<a href="DEs_and_Spikes.html" title="backward to &quot;3 Differential Equations and Spiking Neuron Models&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="index.html" title="up to &quot;Computational Modeling for Psychology&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Projects.html" title="forward to &quot;5 Topics for Final Projects&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div></div></div><div id="contextindicator">&nbsp;</div></body></html>