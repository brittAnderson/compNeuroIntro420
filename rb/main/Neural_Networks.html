<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=0.8"/><title>4&nbsp;Neural Networks</title><link rel="stylesheet" type="text/css" href="scribble.css" title="default"/><link rel="stylesheet" type="text/css" href="racket.css" title="default"/><link rel="stylesheet" type="text/css" href="figure.css" title="default"/><link rel="stylesheet" type="text/css" href="autobib.css" title="default"/><link rel="stylesheet" type="text/css" href="scribble-style.css" title="default"/><script type="text/javascript" src="scribble-common.js"></script><script type="text/javascript" src="figure.js"></script><script type="text/javascript">
(function() {document.write('<scr' + 'ipt type="text/javascript" src="MathJax/MathJax.js?config=default"></scr' + 'ipt>');})();
</script><!--[if IE 6]><style type="text/css">.SIEHidden { overflow: hidden; }</style><![endif]--></head><body id="scribble-racket-lang-org"><div class="tocset"><div class="tocview"><div class="tocviewlist tocviewlisttopspace"><div class="tocviewtitle"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_0&quot;);">&#9660;</a></td><td></td><td><a href="index.html" class="tocviewlink" data-pltdoc="x">Computational Modeling for Psychology</a></td></tr></table></div><div class="tocviewsublisttop" style="display: block;" id="tocview_0"><table cellspacing="0" cellpadding="0"><tr><td align="right">1&nbsp;</td><td><a href="Introductory_Material.html" class="tocviewlink" data-pltdoc="x">Introduction and Computing Requirements</a></td></tr><tr><td align="right">2&nbsp;</td><td><a href="Computation_and_Cognition.html" class="tocviewlink" data-pltdoc="x">What is Computation and is Cognition Computable?</a></td></tr><tr><td align="right">3&nbsp;</td><td><a href="DEs_and_Spikes.html" class="tocviewlink" data-pltdoc="x">Differential Equations and Spiking Neuron Models</a></td></tr><tr><td align="right">4&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">Neural Networks</a></td></tr><tr><td align="right">5&nbsp;</td><td><a href="Projects.html" class="tocviewlink" data-pltdoc="x">Topics for Final Projects</a></td></tr></table></div></div><div class="tocviewlist"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_1&quot;);">&#9658;</a></td><td>4&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">Neural Networks</a></td></tr></table><div class="tocviewsublistbottom" style="display: none;" id="tocview_1"><table cellspacing="0" cellpadding="0"><tr><td align="right">4.1&nbsp;</td><td><a href="#%28part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks%29" class="tocviewlink" data-pltdoc="x">Introduction to Linear Algebra and Neural Networks</a></td></tr><tr><td align="right">4.2&nbsp;</td><td><a href="#%28part._.The_.Math_.That_.Underlies_.Neural_.Networks_%29" class="tocviewlink" data-pltdoc="x">The Math That Underlies Neural Networks?</a></td></tr><tr><td align="right">4.3&nbsp;</td><td><a href="#%28part._.Perceptrons%29" class="tocviewlink" data-pltdoc="x">Perceptrons</a></td></tr><tr><td align="right">4.4&nbsp;</td><td><a href="#%28part._.Hopfield_.Networks%29" class="tocviewlink" data-pltdoc="x">Hopfield Networks</a></td></tr></table></div></div></div><div class="tocsub"><div class="tocsubtitle">On this page:</div><table class="tocsublist" cellspacing="0"><tr><td><span class="tocsublinknumber">4.1<tt>&nbsp;</tt></span><a href="#%28part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks%29" class="tocsubseclink" data-pltdoc="x">Introduction to Linear Algebra and Neural Networks</a></td></tr><tr><td><span class="tocsublinknumber">4.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Linear_.Algebra_.Goals%29" class="tocsubseclink" data-pltdoc="x">Linear Algebra Goals</a></td></tr><tr><td><span class="tocsublinknumber">4.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Drawing_.Cellular_.Automata%29" class="tocsubseclink" data-pltdoc="x">Drawing Cellular Automata</a></td></tr><tr><td><span class="tocsublinknumber">4.1.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Comments_on_the_programmatic_implementation%29" class="tocsubseclink" data-pltdoc="x">Comments on the programmatic implementation</a></td></tr><tr><td><span class="tocsublinknumber">4.1.3<tt>&nbsp;</tt></span><a href="#%28part._.More_.Lessons_from_.Cellular_.Automata%29" class="tocsubseclink" data-pltdoc="x">More Lessons from Cellular Automata</a></td></tr><tr><td><span class="tocsublinknumber">4.2<tt>&nbsp;</tt></span><a href="#%28part._.The_.Math_.That_.Underlies_.Neural_.Networks_%29" class="tocsubseclink" data-pltdoc="x">The Math That Underlies Neural Networks?</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Linear_.Algebra%29" class="tocsubseclink" data-pltdoc="x">Linear Algebra</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Important_.Objects_and_.Operations%29" class="tocsubseclink" data-pltdoc="x">Important Objects and Operations</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Adding_.Matrices%29" class="tocsubseclink" data-pltdoc="x">Adding Matrices</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Activity%29" class="tocsubseclink" data-pltdoc="x">Activity</a></td></tr><tr><td><span class="tocsublinknumber">4.2.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Common_.Notational_.Conventions_for_.Vectors_and_.Matrices%29" class="tocsubseclink" data-pltdoc="x">Common Notational Conventions for Vectors and Matrices</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2<tt>&nbsp;</tt></span><a href="#%28part._.What_is_a_.Neural_.Network_%29" class="tocsubseclink" data-pltdoc="x">What is a Neural Network?</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Non-linearities%29" class="tocsubseclink" data-pltdoc="x">Non-<wbr></wbr>linearities</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Exercise_.X.O.R%29" class="tocsubseclink" data-pltdoc="x">Exercise XOR</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.2<tt>&nbsp;</tt></span><a href="#%28part._.Connections%29" class="tocsubseclink" data-pltdoc="x">Connections</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.3<tt>&nbsp;</tt></span><a href="#%28part._.Boolean_.Logic%29" class="tocsubseclink" data-pltdoc="x">Boolean Logic</a></td></tr><tr><td><span class="tocsublinknumber">4.2.2.4<tt>&nbsp;</tt></span><a href="#%28part.__.First_.Order_.Logic_-_.Truth_.Tables%29" class="tocsubseclink" data-pltdoc="x"> First Order Logic -<wbr></wbr> Truth Tables</a></td></tr><tr><td><span class="tocsublinknumber">4.3<tt>&nbsp;</tt></span><a href="#%28part._.Perceptrons%29" class="tocsubseclink" data-pltdoc="x">Perceptrons</a></td></tr><tr><td><span class="tocsublinknumber">4.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Goals%29" class="tocsubseclink" data-pltdoc="x">Goals</a></td></tr><tr><td><span class="tocsublinknumber">4.3.2<tt>&nbsp;</tt></span><a href="#%28part._.Perceptron_.History_and_.Implementation%29" class="tocsubseclink" data-pltdoc="x">Perceptron History and Implementation</a></td></tr><tr><td><span class="tocsublinknumber">4.3.3<tt>&nbsp;</tt></span><a href="#%28part._.The_.Perceptron_.Rules%29" class="tocsubseclink" data-pltdoc="x">The Perceptron Rules</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4<tt>&nbsp;</tt></span><a href="#%28part._.You_.Are_.The_.Perceptron%29" class="tocsubseclink" data-pltdoc="x">You Are The Perceptron</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.1<tt>&nbsp;</tt></span><a href="#%28part._.A_simple_data_set%29" class="tocsubseclink" data-pltdoc="x">A simple data set</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.2<tt>&nbsp;</tt></span><a href="#%28part._.What_does_it_all_mean__.How_is_the_.Perceptron_.Learning_%29" class="tocsubseclink" data-pltdoc="x">What does it all mean? How is the Perceptron Learning?</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.3<tt>&nbsp;</tt></span><a href="#%28part._.Bias%29" class="tocsubseclink" data-pltdoc="x">Bias</a></td></tr><tr><td><span class="tocsublinknumber">4.3.4.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Geometrical_.Thinking%29" class="tocsubseclink" data-pltdoc="x">Geometrical Thinking</a></td></tr><tr><td><span class="tocsublinknumber">4.3.5<tt>&nbsp;</tt></span><a href="#%28part._.The_.Delta_.Rule_-_.Homework%29" class="tocsubseclink" data-pltdoc="x">The Delta Rule -<wbr></wbr> Homework</a></td></tr><tr><td><span class="tocsublinknumber"></span><a href="#%28part._ref~3aperceptron%29" class="tocsubseclink" data-pltdoc="x">Perceptron Bibliography</a></td></tr><tr><td><span class="tocsublinknumber">4.4<tt>&nbsp;</tt></span><a href="#%28part._.Hopfield_.Networks%29" class="tocsubseclink" data-pltdoc="x">Hopfield Networks</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1<tt>&nbsp;</tt></span><a href="#%28part._.Not_all_.Networks_are_the_.Same%29" class="tocsubseclink" data-pltdoc="x">Not all Networks are the Same</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.1<tt>&nbsp;</tt></span><a href="#%28part._.How_does_a_network_like_this_work_%29" class="tocsubseclink" data-pltdoc="x">How does a network like this work?</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Test_your_understanding_%29" class="tocsubseclink" data-pltdoc="x">Test your understanding:</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.3<tt>&nbsp;</tt></span><a href="#%28part._.A_.Worked_.Example%29" class="tocsubseclink" data-pltdoc="x">A Worked Example</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Distance_.Metrics%29" class="tocsubseclink" data-pltdoc="x">Distance Metrics</a></td></tr><tr><td><span class="tocsublinknumber">4.4.1.4<tt>&nbsp;</tt></span><a href="#%28part._.Hebb_s_.Outer_.Product_.Rule%29" class="tocsubseclink" data-pltdoc="x">Hebb&rsquo;s Outer Product Rule</a></td></tr><tr><td><span class="tocsublinknumber">4.4.2<tt>&nbsp;</tt></span><a href="#%28part._.Hopfield_.Homework_.Description__.Robustness_to_.Noise%29" class="tocsubseclink" data-pltdoc="x">Hopfield Homework Description:<span class="mywbr"> &nbsp;</span> Robustness to Noise</a></td></tr><tr><td><span class="tocsublinknumber"></span><a href="#%28part._ref~3ahopfield%29" class="tocsubseclink" data-pltdoc="x">Hopfield Bibliography</a></td></tr></table></div></div><div class="maincolumn"><div class="main"><div class="navsettop"><span class="navleft"><div class="nosearchform"></div>&nbsp;&nbsp;<span class="tocsettoggle">&nbsp;&nbsp;<a href="javascript:void(0);" title="show/hide table of contents" onclick="TocsetToggle();">contents</a></span></span><span class="navright">&nbsp;&nbsp;<a href="DEs_and_Spikes.html" title="backward to &quot;3 Differential Equations and Spiking Neuron Models&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="index.html" title="up to &quot;Computational Modeling for Psychology&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Projects.html" title="forward to &quot;5 Topics for Final Projects&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div><h3>4<tt>&nbsp;</tt><a name="(part._.Neural._.Networks)"></a>Neural Networks</h3><h4>4.1<tt>&nbsp;</tt><a name="(part._.Introduction_to_.Linear_.Algebra_and_.Neural_.Networks)"></a>Introduction to Linear Algebra and Neural Networks</h4><h5>4.1.1<tt>&nbsp;</tt><a name="(part._.Linear_.Algebra_.Goals)"></a>Linear Algebra Goals</h5><p><div class="SIntrapara">Our goal for the next few lessons is to come to understand
</div><div class="SIntrapara"><ul><li><p>What is a neural network?</p></li><li><p>What mathematics are needed to build a neural network?</p></li><li><p>How can neural networks help us understand cognition?</p></li></ul></div></p><p>As a first illustration of some of the key ideas we will execute a simple cellular automata rule. What I hope to emphasize through this exercise is that whenever you can get the computer to do a repetitive task do so. It will do it much better than you. And even if it takes you days to get the program right for many task you will quickly save the time in the long run. Second, we are using a simple rule (as you will shortly see). But even though the rule is local it yields impressive global structure. And very slight tweaks in this local rule can lead to large macroscopic changes. While the variation in our rule is very limited the array of behaviors we can observe is vast. <span class="refelem"><span class="refcolumn"><span class="refcontent">Match these features to facts about neurons. Extend them to what you believe will be their application in neural networks.</span></span></span></p><h5>4.1.2<tt>&nbsp;</tt><a name="(part._.Drawing_.Cellular_.Automata)"></a>Drawing Cellular Automata</h5><p>This activity has several stages. For the first stage make sure you can load the file <a href="&quot;./../code/ca.rkt&quot;"></a> into Dr Racket and that it runs.</p><p>Next, pick a number between 0 and 255 inclusive. In your interactive window use the function <span class="stt">rule-tester</span> to generate the input-output pairing for your rule like so.</p><p><div class="SIntrapara">Testing Rule 22</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">rule-tester</span><span class="hspace">&nbsp;</span><span class="RktVal">22</span><span class="hspace">&nbsp;</span><span class="RktSym">test-set</span><span class="RktPn">)</span></td></tr><tr><td><table cellspacing="0" cellpadding="0"><tr><td><p><span class="RktOut">in (w w w) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (w w b) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (w b w) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (w b b) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b w w) out b</span></p></td></tr><tr><td><p><span class="RktOut">in (b w b) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b b w) out w</span></p></td></tr><tr><td><p><span class="RktOut">in (b b b) out w</span></p></td></tr></table></td></tr></table></blockquote></div></p><p>Use your rule and a piece of graph paper to implement your rule.</p><p>Color a single black square in the middle of the top row. Then moving down one row and working left to right implement your rule by coloring in the appropriate square.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="grid.png" alt="" width="359" height="240"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3agrid-automata))" x-target-lift="Figure"></a>Figure&nbsp;5: </span>Nearest Neighbors in the Grid</span></p></blockquote><p>For example, if the boxes 1, 2, and 3 were &rsquo;w, &rsquo;w, and &rsquo;b I could color the square with the question mark black. Then I would move one to the right and square 2 would become my new number 1 and so on.</p><p>Complete several rows following your rule.</p><p>What you have probably noticed is that this is tedious and mistake prone, but your rule is a good example of a function. A function can be conceived as a set of pairs. The first element of the pair is the input, and the second element of the pair is the output. Functions require that each input element be unique. Implementing your rule  makes you the metaphorical neuron deciding whether or not to fire (color the square black) based on the input you receive from neighboring neurons.</p><p>Having learned how tedious and error prone this process explore some of the other rules using the functions in <span class="stt">ca.rkt</span>. The simplest method is to use the function <span class="stt">d-r-a &lt;some-rule-number&gt;</span>. You can adjust the size and scale with various optional arguments and even print it to a file if you find one you like. Here is one of my favorites as a demonstration.</p><p><div class="SIntrapara">Rule 110</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">d-r-a</span><span class="hspace">&nbsp;</span><span class="RktVal">110</span><span class="hspace">&nbsp;</span><span class="RktPn">#:num-rows</span><span class="hspace">&nbsp;</span><span class="RktVal">100</span><span class="hspace">&nbsp;</span><span class="RktPn">#:num-cols</span><span class="hspace">&nbsp;</span><span class="RktVal">100</span><span class="hspace">&nbsp;</span><span class="RktPn">#:scale</span><span class="hspace">&nbsp;</span><span class="RktVal">3</span><span class="RktPn">)</span></td></tr><tr><td><p><img src="pict_8.png" alt="image" width="300" height="303"/></p></td></tr></table></blockquote></div></p><p><div class="SIntrapara">What are the lessons learned from this exercise?
</div><div class="SIntrapara"><ol><li><p>Repetitive actions are hard. We (humans) make mistakes following even simple rules for a large number of repeated steps. Better to let the computer do it since that is where its strengths lie.</p></li><li><p>Complex global patterns can emerge from local actions. Each neuron is only responding to its immediate right and left yet global structures emerge.</p></li><li><p>These characteristics seem similar to brain activity. Each neuron in the brain is just one of many. Whether a neuron spikes or not is a consequence of its own state and its inputs (like the neighbors in the grid example).</p></li><li><p>From each neuron making a local computation, global patterns of complex activity can emerge.</p></li><li><p>Maybe by programming something similar to this system we can get insights into brain activity.</p></li></ol></div></p><h5>4.1.2.1<tt>&nbsp;</tt><a name="(part._.Comments_on_the_programmatic_implementation)"></a>Comments on the programmatic implementation</h5><p>The code in <span class="stt">ca.rkt</span> involves a lot of looping. I used <span style="font-style: italic">for</span> loops extensively, though sometimes these were <span class="stt">for/fold</span> variants. We need to inch along the columns and down the rows. The plotting used the built in functionality of <span style="font-weight: bold">racket</span> for generating pictures as output.</p><p>The potentially more tricky part was going from a number (in decimal) to a binary representation that had the right number of places occupied. I ended going back and forth between strings and lists to get what I wanted. This was undoubtedly a kludge, but there is a slogan to first get it working, and then make it better. Trying to be too perfect and too elegant can cost you time in the long run. It is often easier to revise a functioning program then write one from the start.</p><p>Initially I did not have all the testing code, because I was adapting code I had written in the past. However, when things did not work it turned out I went faster by slowing down and writing code that allowed me to inspect the state of my various variables, and individually try out the small functions on test input.</p><h5>4.1.3<tt>&nbsp;</tt><a name="(part._.More_.Lessons_from_.Cellular_.Automata)"></a>More Lessons from Cellular Automata</h5><p>Cellular automata demonstrate some basic lessons that we will make use of when thinking about neural networks. One of these points is that there may be simple representations for complex entities. If we can find the right language for representation we may get concision and repeatability as by-products. This is demonstrated by the <a href="https://plato.stanford.edu/entries/cellular-automata/supplement.html">naming convention for the rules of cellular automata</a>.</p><p>In emphasizing that local decisions can produce interesting global effects it may be interesting to examine other similar uses of the cellular automata idea. One famous and visually pleasing one is the <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Game of Life</a>.</p><p>The analogy of automata to simple neurons may be deeper than at first it appears. Some very famous thinkers connected the two. One of the most brilliant people of all time, John von Neumann, was working on a book about automata and the brain at the time of his death. I have linked to a commentary in case you are interested in reading further see <a href="http://www.ams.org/bull/1958-64-03/S0002-9904-1958-10214-1/S0002-9904-1958-10214-1.pdf">Claude Shannon (pdf)</a> as well as to a pdf <a href="https://complexityexplorer.s3.amazonaws.com/supplemental_materials/5.6+Artificial+Life/The+Computer+and+The+Brain_text.pdf">copy</a> of the book: <a href="https://ocul-wtl.primo.exlibrisgroup.com/permalink/01OCUL_WTL/vk29fk/alma994863683505162">The Computer and the Brain</a>).</p><p>A contemporary mathematician and the inventor of the Mathematica software system also believes that cellular automata may be a theory of everything. See what Stephen Wolfram <a href="http://www.wolframscience.com">thinks</a>.</p><h4>4.2<tt>&nbsp;</tt><a name="(part._.The_.Math_.That_.Underlies_.Neural_.Networks_)"></a>The Math That Underlies Neural Networks?</h4><h5>4.2.1<tt>&nbsp;</tt><a name="(part._.Linear_.Algebra)"></a>Linear Algebra</h5><p>The math at the heart of neural networks and their computer implementation is <span style="font-style: italic"><span style="font-weight: bold">linear algebra</span></span>. For us, the section of linear algebra we are going to need is mostly limited to vectors, matrices and how to add and multiply them.</p><h5>4.2.1.1<tt>&nbsp;</tt><a name="(part._.Important_.Objects_and_.Operations)"></a>Important Objects and Operations</h5><ol><li><p>Vectors</p></li><li><p>Matrices</p></li><li><p>Scalars</p></li><li><p>Addition</p></li><li><p>Multiplication (scalar and matrix)</p></li><li><p>Transposition</p></li><li><p>Inverse</p></li></ol><h5>4.2.1.1.1<tt>&nbsp;</tt><a name="(part._.Adding_.Matrices)"></a>Adding Matrices</h5><p>To gain some hands on familiarity with the manipulation of matrices and vectors we will try to do some hand and programming exercises for some of the fundamental operations of addition and multiplication. We will also thereby learn that some of the rules we learned for numbers (such as a * b = b * a) do not always apply in other mathematical realms.</p><p>There are in fact many ways to think about what a vector is.</p><p>It can be thought of as a column (or row of numbers).
More abstractly it is an object (arrow) with magnitude and direction.
Most abstractly it is anything that obeys the requirements of a vector space.</p><p>For particular circumstances one or another of the different definitions may serve our purposes better. In application to neural networks we often just use the first definition, a column of numbers, but the second can be more helpful for developing our geometric intuitions about what various learning rules are doing and how they do it.</p><p>Similarly, we often just consider a matrix as a collection of vectors or as a rectangular (2-D) collection of numbers.</p><h5>4.2.1.1.2<tt>&nbsp;</tt><a name="(part._.Activity)"></a>Activity</h5><p>Look up how racket handles <a href="https://docs.racket-lang.org/math/matrices.html">matrices and vectors</a>. Here is a very simple <a href="./../code/la-demo.rkt">file</a> to try and get started.</p><p><span style="font-weight: bold">Important</span>: vectors are a special datatype in Racket, and the vector type is probably not what you want to be using. Look for matrices and linear algebra.</p><p>Make two arrays and make them the same size<span class="refelem"><span class="refcolumn"><span class="refcontent">What is the <span style="font-style: italic">size</span> of a matrix?</span></span></span>.</p><p>Add them together in both orders (A + B and B + A). How does one add an array that itself has numerous different numbers?</p><p>Then do the same for multiplication. Note that there are particular requirements for the sizes of matrices in order that it is possible to multiply them in both directions. What is that rule?</p><p>What is the name for the property of having A*B = B*A?</p><h5>4.2.1.2<tt>&nbsp;</tt><a name="(part._.Common_.Notational_.Conventions_for_.Vectors_and_.Matrices)"></a>Common Notational Conventions for Vectors and Matrices</h5><p>Vectors tend to be notated as <span style="font-style: italic">lower case</span> letters, often in bold, such
as <span class="math">\mathbf{a}</span>. They are also occasionally represented with little
arrows on top such as <span class="math">\overrightarrow{\textbf{a}}</span>.</p><p>Matrices tend to be notated as <span style="font-style: italic">upper case</span> letters, typically in bold,
such as <span class="math">\mathbf{M}</span>.</p><p>Good things to know: what is an <span style="font-style: italic">inner product</span>? How do you compute it in racket?</p><h5>4.2.2<tt>&nbsp;</tt><a name="(part._.What_is_a_.Neural_.Network_)"></a>What is a Neural Network?</h5><p>What is a Neural Network? It is a brain inspired computational approach
in which "neurons" compute functions of their inputs and pass on a
<span style="font-style: italic">weighted</span> proportion to the next neuron in the chain.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="nn.png" alt="" width="400" height="136"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig-nn))" x-target-lift="Figure"></a>Figure&nbsp;6: </span>simple schematic of the basics of a neural network. This is an image for a single neuron. The input has three elements and each of these connects to the same neuron ("node 1"). The activity at those nodes is filtered by the weights, which are specific for each of the inputs. These three processed inputs are combined to generate the output from this neuron. For multiple layers this output becomes an input for the next neuron along the chain.</span></p></blockquote><h5>4.2.2.1<tt>&nbsp;</tt><a name="(part._.Non-linearities)"></a>Non-linearities</h5><p>The spiking of a biological neuron is non-linear. You saw this in both the integrate and fire and Hodgkin and Huxley models you programmed. The lines on those plots you created are not, for the most part, straight. Perhaps the simplest way to incorporate a non-linearity into our artificial neuron is to give it a threshold, like we did for the integrate and fire model. When activity exceeds the threshold (which we will usually designate with a capital Greek Theta <span class="math">\Theta</span> then the neuron is set to 1 and if it is not firing it is set to 0 (like the "w" &#8594; 0; "b" &#8594; 1 mapping we used for the cellular automata).</p><p><div class="math">\begin{equation}
\mbox{if } I_1 \times w_{1,1} + I_2 \times w_{2,1} + I_3 \times w_{3,1} &gt; \Theta \mbox{ then } Output = 1
\end{equation}</div></p><p>What this equation shows is that Inputs (the <span class="math">I</span>s) are passed to a neuron. Those inputs have something like a synapse. That is designated by the w&rsquo;s. Those weights are how tightly the input and internal activity of our artificial neuron is coupled. The reason for all the subscripts is to try and help you see the similarity between this equation and the inner product and matrix multiplication rules you just worked on programming. The activity of the neuron is a sort of internal state, and then, based on the comparison of that activity to the threshold, you can envision the neuron spiking or not, meaning it has value 1 or 0. Mathematically, the weighted sum is fed into a threshold function that compares the value to a threshold <span class="math">\Theta</span>, and passes on the value 1 if it is greater than the threshold and 0 (sometimes <span class="math">-1</span> rather than zero is chosen for the inactive state because there are certain computational conveniences in doing so).</p><p>To prepare you for the next steps in writing a simple percetron (the earliest form of artificial neural network), you should try to answer the followign questons.</p><p><div class="SIntrapara">Questions:
</div><div class="SIntrapara"><ol><li><p>What, geometrically speaking, is a plane?</p></li><li><p>What is a hyperplane?</p></li><li><p>What is linearly separability and how does that relate to planes and
hyperplanes?</p></li></ol></div></p><p>One of our first efforts will be to code a <span style="font-style: italic">perceptron</span> to solve the XOR problem. In order for this to happen you need to know a bit about <span style="font-style: italic">Boolean</span> functions and what an XOR problem actually is.</p><p><span style="font-weight: bold">Examples of Boolean Functions and How They Map onto our Neural Network Intuitions</span></p><p>The "AND" Operation/Function</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_9.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3aand))" x-target-lift="Figure"></a>Figure&nbsp;7: </span>The <span style="font-style: italic">and</span> operation is true when both its inputs are true.</span></p></blockquote><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_10.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3aor))" x-target-lift="Figure"></a>Figure&nbsp;8: </span>The <span style="font-style: italic">or</span> operation is true if either or both of its inputs are true.</span></p></blockquote><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_11.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3axor))" x-target-lift="Figure"></a>Figure&nbsp;9: </span>The <span style="font-style: italic">xor</span> is true when one or the other, but not both of the inputs are true. It is exclusively an or function.</span></p></blockquote><p>This short <a href="https://media.nature.com/m685/nature-assets/nbt/journal/v26/n2/images/nbt1386-F1.gif">article</a> provides a nice example of linear separability and some basics of what a neural network is.</p><h5>4.2.2.1.1<tt>&nbsp;</tt><a name="(part._.Exercise_.X.O.R)"></a>Exercise XOR</h5><p>Using only <span style="font-style: italic">not</span>, <span style="font-style: italic">and</span>, and <span style="font-style: italic">or</span> operations draw the diagram that allows you to compute in two steps the <span style="font-style: italic">xor</span> operation. You will need this to code it up as a perceptron.</p><h5>4.2.2.2<tt>&nbsp;</tt><a name="(part._.Connections)"></a>Connections</h5><p>Can neural networks encode logic? Is the processing zeros and ones enough to capture the richness of human intellectual activity?</p><p>There is a long tradition of representing human thought as the consequence of some sort of calculation of two values (true or false). If you have two values you can swap out 1&rsquo;s and 0&rsquo;s for the true and false in your calculation. They even seem to obey similar laws. If you the conjunction (AND) of two true things it is only true when both are true. If you take T = 1, then T &#8743; T is the same as <span class="math">1~\times~1</span>.</p><p>We will next build up a simple threshold neural unit and try to calculate some of these truth functions with our neuron. We will build simple neurons for truth tables (like those that follow), and string them together into an argument. Then we can feed values of T and F into our network and let it calculate the XOR problem.</p><h5>4.2.2.3<tt>&nbsp;</tt><a name="(part._.Boolean_.Logic)"></a>Boolean Logic</h5><p>George Boole, Author of the <span style="font-style: italic">Laws of Thought</span></p><ul><li><p>Read the <a href="https://archive.org/details/investigationofl00boolrich">book</a> on Archive.org</p></li><li><p>Read about <a href="https://plato.stanford.edu/entries/boole/#LifWor">George Boole</a></p></li></ul><h5>4.2.2.4<tt>&nbsp;</tt><a name="(part.__.First_.Order_.Logic_-_.Truth_.Tables)"></a> First Order Logic - Truth Tables</h5><p><span style="font-weight: bold">Or</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Or</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr></table></p><p><span style="font-weight: bold">And</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Or</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr></table></p><p><span style="font-weight: bold">Nand</span></p><p><table cellspacing="0" cellpadding="0"><tr><td><p><span style="font-weight: bold">Pr A</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Pr B</span></p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p><span style="font-weight: bold">Or</span></p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td></tr><tr><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>1</p></td><td><p><span class="hspace">&nbsp;</span></p></td><td><p>0</p></td></tr></table></p><h4>4.3<tt>&nbsp;</tt><a name="(part._.Perceptrons)"></a>Perceptrons</h4><h5>4.3.1<tt>&nbsp;</tt><a name="(part._.Goals)"></a>Goals</h5><p>The goal for this file is to share the idea of a perceptron, the mathematical formula for updating one, and iniate the process of coding a simple implementation that we will adapt to the delta rule.</p><h5>4.3.2<tt>&nbsp;</tt><a name="(part._.Perceptron_.History_and_.Implementation)"></a>Perceptron History and Implementation</h5><p>The perceptron was the invention of a psychologist, <a href="http://dspace.library.cornell.edu/bitstream/1813/18965/2/Rosenblatt_Frank_1971.pdf">Frank Rosenblatt</a>.  He was not a computer scientist. Though he obviously had a bit of the mathematician in him.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="Mark_I_perceptron.jpeg" alt=""/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3amark.I))" x-target-lift="Figure"></a>Figure&nbsp;10: </span>The Perceptron Mark I</span></p></blockquote><p>Details to be found on the <a href="https://en.wikipedia.org/wiki/Perceptron">wikipedia page</a>.</p><p>Those interested in some interesting background reading could consult his over 600 page book entitled <a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015039846566&amp;view=1up&amp;seq=9">Principles of Neurodynamics</a> or this <a href="https://link.springer.com/book/10.1007/978-3-642-70911-1">historical review</a>.</p><p>From the foreward of that book we have the following quote:</p><p>"For this writer, the perceptron program is not primarily concerned with the invention of devices for "artificial intelligence", but rather with investigating the physical structures and neurodynamic principles which under lie "natural intelligence". A perceptron is first and fore most a brain model, not an invention for pattern recognition. As a brain model, its utility is in enabling us to determine the physical conditions for the emergence of various psychological properties."</p><h5>4.3.3<tt>&nbsp;</tt><a name="(part._.The_.Perceptron_.Rules)"></a>The Perceptron Rules</h5><p>The perceptron rules are the equations that characterize what a perceptron is, and what it does in contact with experience, so that it can learn and revise its behavior. A lot can be done with these simple equations.</p><p><span class="math">I = \sum_{i=1}^{n} w_i~x_i</span></p><p>If <span class="math">I \ge T</span> then <span class="math">y = +1</span> else if <span class="math">I &lt; T</span> then <span class="math">y = -1</span></p><p>If the answer was correct, then <span class="math">\beta = +1</span>, else if the
answer was incorrect then <span class="math">\beta = -1</span>.</p><p>Updating is done by <span class="math">\mathbf{w_{new}} =
\mathbf{w_{old}} + \beta y \mathbf{x}</span></p><h5>4.3.4<tt>&nbsp;</tt><a name="(part._.You_.Are_.The_.Perceptron)"></a>You Are The Perceptron</h5><p>This is a pencil and paper exercise. Before coding it is often a good idea to try and work the basics out by hand. This may be a flow chart or a simple hand worked example. This both gives you a simple test case to compare your code against, but more importantly makes sure that you understand what you are trying to code. Let&rsquo;s make sure you understand how to compute the perceptron learning rule, but doing a simple case by hand.</p><p>Beginning with an input of <span class="math">\begin{bmatrix}0.3 \\ 0.7 \end{bmatrix}</span>, an initial set of weights of <span class="math">\begin{bmatrix}-0.6 \\ 0.8 \end{bmatrix}</span>, and a <span style="font-weight: bold">class</span> of 1. Compute the value of the new weight vector with pen and paper.</p><h5>4.3.4.1<tt>&nbsp;</tt><a name="(part._.A_simple_data_set)"></a>A simple data set</h5><p>For these data there are two dimensions or features (the first and second columns) and the third colum represents their <span style="font-style: italic">class</span>.</p><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="RktPn">(</span><span class="RktSym">matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktPn">[</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal">0.7</span><span class="hspace">&nbsp;</span><span class="RktVal">1.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.5</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal">0.7</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="hspace">&nbsp;</span><span class="RktVal">1.0</span><span class="RktPn">]</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.2</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-0</span>.8</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr></table></blockquote><p>Using the starting weight above write code to iteratively compute a new weight from each input and it&rsquo;s class and using the current weight. If you can, save each updated weight so you can see how they change, but if you can&rsquo;t still try to use a for construct to iterate through these data and see how the weights change.</p><p>In broad outlines you will need to decide on a data structure. You can use a matrix as I have here, but it may be easier to just use a list to start. For example <span class="RktPn">(</span><span class="RktSym">list</span><span class="stt"> </span><span class="RktPn">(</span><span class="RktSym">list</span><span class="stt"> </span><span class="RktVal">0.3</span><span class="stt"> </span><span class="RktVal">0.7</span><span class="RktPn">)</span><span class="stt"> </span><span class="RktVal">1.0</span><span class="RktPn">)</span>. The first element of the list would be the input data and the last item the desired class. You could create a list of list of such elements to capture the matrix I have displayed above.</p><p>This progressive updating of the weight vector is the <span style="font-style: italic">learning</span>. Note that sometimes our initial weight vector classifies incorrectly. How does it do after one complete cycle through all the training examples?</p><p><div class="SIntrapara">Checking our Learned Weight For One Input</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="stt">&gt; </span><span class="RktPn">(</span><span class="RktSym">let</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktPn">[</span><span class="RktSym">in-class</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span>.0</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">if</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">=</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">if</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">&gt;=</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">matrix-ref</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">matrix*</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">row-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.6</span><span class="hspace">&nbsp;</span><span class="RktVal">0.3</span><span class="RktPn">]</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktPn">(</span><span class="RktSym">col-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal">1.2</span><span class="hspace">&nbsp;</span><span class="RktVal">2.3</span><span class="RktPn">]</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">0</span><span class="hspace">&nbsp;</span><span class="RktVal">0</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">0.0</span><span class="RktPn">)</span></td></tr><tr><td><span class="hspace">&nbsp;&nbsp;</span><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="RktVal">1</span><span class="hspace">&nbsp;</span><span class="RktVal"><span class="nobreak">-1</span></span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktSym">in-class</span><span class="RktPn">)</span><span class="hspace">&nbsp;</span><span class="RktVal">"correct"</span><span class="hspace">&nbsp;</span><span class="RktVal">"incorrect"</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr></table></td></tr><tr><td><p><span class="RktRes">"correct"</span></p></td></tr></table></blockquote></div></p><h5>4.3.4.2<tt>&nbsp;</tt><a name="(part._.What_does_it_all_mean__.How_is_the_.Perceptron_.Learning_)"></a>What does it all mean? How is the Perceptron Learning?</h5><p><div class="SIntrapara">Changing Weights as Vectors</div><div class="SIntrapara"><blockquote class="SCodeFlow"><table cellspacing="0" cellpadding="0" class="RktBlk"><tr><td><span class="RktPn">(</span><span class="RktSym">wt-plot</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">one-loop-through-data</span><span class="hspace">&nbsp;</span><span class="RktSym">my-data</span><span class="hspace">&nbsp;</span><span class="RktPn">(</span><span class="RktSym">col-matrix</span><span class="hspace">&nbsp;</span><span class="RktPn">[</span><span class="RktVal"><span class="nobreak">-0</span>.6</span><span class="hspace">&nbsp;</span><span class="RktVal">0.8</span><span class="RktPn">]</span><span class="RktPn">)</span><span class="RktPn">)</span><span class="RktPn">)</span></td></tr><tr><td><p><img src="pict_12.png" alt="image" width="400" height="400"/></p></td></tr></table></blockquote></div></p><p>These functions and the <span class="stt">my-data</span> are in the file <a href="./../code/perceptron-rule.rkt">perceptron-rule.rkt</a>. Each time through the perceptron rule I compute the new weights and use the first position as the &rsquo;x&rsquo; value and the second position as the &rsquo;y&rsquo; value to plot vectors on an &rsquo;x-y&rsquo; plane. You can imagine that as we iterate through the data we are rotating the vectors around an origin. The decision plane is perpendicular to the vectors and anchored at the bottom of the arrows. If you compare this to the location of the data points (which you can add to the plot by editing the functions in the linked file) you will see that the rule is learning to find the decision plane that puts all of one class on one side of the line and all of the other class on the other side. That is why it is limited to problems that are linearly separable!</p><h5>4.3.4.3<tt>&nbsp;</tt><a name="(part._.Bias)"></a>Bias</h5><p>These data were selected such that the base of the vector could separate them while anchored at zero. However, for many data sets you not only need to learn what direction to point the vector, but you also need to learn where to anchor the vector. This is done by including a <span style="font-weight: bold">bias weight</span>. Add an extra dimension to your weight vector and your inputs. For the inputs it will just be a constant value of 1.0, but this extra, bias weight, will also be learned and allows you to achieve, effectively, a translation away from the origin to be able to separate points that are more heterogeneously scattered.</p><h5>4.3.4.3.1<tt>&nbsp;</tt><a name="(part._.Geometrical_.Thinking)"></a>Geometrical Thinking</h5><ul><li><p>What is the relation between the inner product of two vectors and the cosine of the angle between them?</p></li><li><p>What is the *sign* for the cosine of angles less than 90 degrees and those greater than 90 degrees?</p></li><li><p> How do these facts help us to answer the question above?</p></li><li><p> Why does this reinforce the advice to think /geometrically/ when thinking about networks and weight vectors?</p></li></ul><h5>4.3.5<tt>&nbsp;</tt><a name="(part._.The_.Delta_.Rule_-_.Homework)"></a>The Delta Rule - Homework</h5><p>The <span style="font-weight: bold"><span style="font-style: italic">Delta Rule</span></span> is another simple learning rule that is a minimal variation on the perceptron rule. It is used more frequently, and it has the spirit of Hebbian learning, which we will learn more about soon. The homework asks you to write code to test and train an artificial neuron using the delta learning rule.</p><ol><li><p>For an easy start create some pseudo random linearly separable points on a a sheet of paper. Label one population as <span style="font-weight: bold">1</span> and the other population as <span style="font-weight: bold">-1</span>.</p></li><li><p>For a more challenging set-up create the data programatically using random numbers and some method that allows you to vary how close or distant the points are to the line of separation, and how many points there are to train on.</p></li><li><p>The Delta Learning rule is: <div class="math">\Delta~w_i = x_i~\eta(desired - observed)</div></p></li><li><p>Submit your code that has your test data in it. Start with an initial random weight and use the delta rule to learn the correct weighting to solve all your training examples. Then test on a new set of points that you did <span style="font-weight: bold">not</span> test on but that are classified according to the same rule. Your code should assess how well the <span style="font-style: italic">trained</span> rule classifies the <span style="font-style: italic">test</span> data.</p></li></ol><p>I have <a href="./../code/perceptron-rule.rkt">some code</a> for the perceptron that might give you some code you could adapt if you have trouble getting started.</p><h5><a name="(part._ref~3aperceptron)"></a>Perceptron Bibliography</h5><p><table cellspacing="0" cellpadding="0" class="AutoBibliography"><tr><td></td></tr></table></p><h4>4.4<tt>&nbsp;</tt><a name="(part._.Hopfield_.Networks)"></a>Hopfield Networks</h4><h5>4.4.1<tt>&nbsp;</tt><a name="(part._.Not_all_.Networks_are_the_.Same)"></a>Not all Networks are the Same</h5><ul><li><p>Feedforward</p></li><li><p>Recurrent</p></li><li><p>Convolutional</p></li><li><p>Multilevel</p></li><li><p>Supervised</p></li><li><p>Unsupervised</p></li></ul><p>The Hopfield network<span class="Autobibref">&nbsp;(<a href="#%28autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79%2C._pp..._2554--25581982https~3a%2F%2Fwww..pnas..org%2Fdoi%2Fabs%2F10..1073%2Fpnas..79..8..2554%29" class="AutobibLink" data-pltdoc="x">Hopfield</a> <a href="#%28autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79%2C._pp..._2554--25581982https~3a%2F%2Fwww..pnas..org%2Fdoi%2Fabs%2F10..1073%2Fpnas..79..8..2554%29" class="AutobibLink" data-pltdoc="x">1982</a>)</span> has taught many lessons, both practical and conceptual. Hopfield showed physicists a new realm for their skills and added recurrent (i.e. feedback) connections to network design (output becomes input). He changed the focus from network architecture to that of a dynamical system. Hopfield showed that the network could remember and it could do some error correction, it could reconstruct the "right" answer from faulty input.</p><blockquote class="Figure"><blockquote class="Centerfigure"><blockquote class="FigureInside"><p><img src="pict_13.png" alt="image" width="400" height="400"/></p></blockquote></blockquote><p class="Centertext"><span class="Legend"><span class="FigureTarget"><a name="(counter._(figure._fig~3ahopfield-net))" x-target-lift="Figure"></a>Figure&nbsp;11: </span>Hopfield Recurrent Connections</span></p></blockquote><h5>4.4.1.1<tt>&nbsp;</tt><a name="(part._.How_does_a_network_like_this_work_)"></a>How does a network like this work?</h5><ul><li><p>Each node has a value.</p></li><li><p>Each of those arrowheads has an associated weight.</p></li><li><p>The line with the "x" indicates that there are no self connections.</p></li><li><p>All other connections for all other units are present and go in both directions.</p></li></ul><h5>4.4.1.2<tt>&nbsp;</tt><a name="(part._.Test_your_understanding_)"></a>Test your understanding:</h5><ol><li><p>Tell me what the input for a network like this with four nodes should look like it terms of the linear algebra constructs we have talked about.</p></li><li><p>A weight is a number associated to each connection. Tell me what the weights should look like in terms of the linear algebra constructs.</p></li><li><p>How might we conceive of "running" the network for one cycle in terms
of the above.</p></li></ol><h5>4.4.1.3<tt>&nbsp;</tt><a name="(part._.A_.Worked_.Example)"></a>A Worked Example</h5><p>Inputs can be thought of as vectors. Although I have drawn the network like a square that shape is really independent of the structure of data flow. Each node needs an input and each node will need a weighted contact to all the other nodes. Consider the following two input patterns and the following weight matrix.
  <div class="math">A = \{1,0,1,0\}^T</div></p><p><div class="math">B = \{0,1,0,1\}^T</div></p><p><div class="math">weights =  \begin{bmatrix}
  0 &amp; -3 &amp; 3 &amp; -3\\
  -3 &amp; 0 &amp; -3 &amp; 3\\
  3 &amp; -3 &amp; 0 &amp; -3\\
  -3 &amp; 3 &amp; -3 &amp; 0\\
  \end{bmatrix}</div></p><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Ask yourself, how do I compute the output? Which comes first: the matrix or the input vector and why?</p></blockquote></blockquote></blockquote><p>Hopfield networks use a threshold rule. This non-linearity is, at least metaphorically, like the threshold that says whether a neuron in the brain or in our integrate and fire model fires. For the Hopfield network our threshold rule says:</p><p><div class="math">output(t)=\{\begin{array}{c} 1\; \mbox{if } t \geq \Theta\\ 0\; \mbox{if } t &lt; \Theta \end{array}</div></p><p><span class="math">\Theta</span> will represent the value of our threshold and for now let&rsquo;s set <span class="math">\Theta = 0</span>.</p><p>To make sure you understand the mechanics of this type of network you should first calculate the output to each of the two input patterns.</p><p>Then, to test your intuition, you should guess what output you would get for an input of <span class="math">\{1,0,0,0\}^T</span>. Calculate it.</p><p>To understand why this is the case, ask yourself whether A or B is <span style="font-weight: bold">closer</span> to this test input? This will hopefully lead you to reflect on what it means, in this context, for one vector to be "closer" to another.</p><h5>4.4.1.3.1<tt>&nbsp;</tt><a name="(part._.Distance_.Metrics)"></a>Distance Metrics</h5><p>Metrics relate to measurement. For some operation to be a distance metric it should meet three intuitive requirements and one that is maybe not as obvious. To measure the distance between two things we need an operation that is binary. That is, it takes two inputs. In this case that would be our two vectors. It&rsquo;s result should always be <span style="font-weight: bold">Non-negative</span>. A negative distance would clearly be meaningless. Our output should be <span style="font-weight: bold">symmetric</span>. Meaning that <span class="math">d(A,B)~d(B,A)</span>. The distance from Waterloo to Toronto ought to come out as the same as going from Toronto to Waterloo. Our metric should be <span style="font-weight: bold">reflexive</span>. The distance from anything to itself ought to be zero. Lastly, to be a distance metric, our operation must obey the <a href="https://en.wikipedia.org/wiki/Triangle_inequality"><span style="font-weight: bold">triangle inequality</span></a></p><p>Now, to understand what the network did, consider your distance measure to be the number of mismatched bits. This metric is called the Hamming distance.</p><p><span style="font-style: italic">Reminder</span>: Don&rsquo;t forget to think about geometry and dynamics.</p><p>For perceptrons we talked about how the weight vector moved the direction it pointed. Here we don&rsquo;t have the weight vector moving, but you can visualize what is happening as updating a point in space. When we first input our four element vector we have a location in 4-D space. We multiply the first row of our weight matrix against our column of the input vector and we see, in effect, what is the effect on our first element (node) of all the other weighted inputs coming in to it. We then "update" that location. Maybe we flip it from a 1 to a zero (or vice versa). Then we try the next row of the weight matrix to see what happens to the second element. As we change the values of our nodes we are creating new points. The sequence of points is a trajectory that we are tracing in the input space. In this simple situation here we only require one pass to reach the final location, but in other settings we might not. In that case we just keep repeating the process until we do. One of the wonderful insights that Hopfield had was that by conceptualizing this process as an "energy" he could mathematically prove that the process would always reach a resting place.</p><h5>4.4.1.4<tt>&nbsp;</tt><a name="(part._.Hebb_s_.Outer_.Product_.Rule)"></a>Hebb&rsquo;s <a href="https://en.wikipedia.org/wiki/Outer_product">Outer Product</a> Rule</h5><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Why is this learning rule called "Hebb&rsquo;s"? And if you don&rsquo;t know who Hebb is let&rsquo;s take a moment to figure that out.</p></blockquote></blockquote></blockquote><p><div class="SIntrapara">The strength of a change in a connection is proportionate to the product of the input and outputs, i.e. <div class="math">\Delta A[i,j] = \eta f[j]g[i]</div> and <div class="math">g[i] = \sum_j~A[i,j]~f[j]</div> therefore, <div class="math">\vec{g} = \mathbf{Af}</div>. </div><div class="SIntrapara"><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>Does it matter that the (\mathbf{W}) comes first?</p></blockquote></blockquote></blockquote></div></p><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>What is an outer product? Can you compute one with racket?</p></blockquote></blockquote></blockquote><h5>4.4.2<tt>&nbsp;</tt><a name="(part._.Hopfield_.Homework_.Description__.Robustness_to_.Noise)"></a>Hopfield Homework Description: Robustness to Noise</h5><p><div class="SIntrapara">Overview of the steps to take:
</div><div class="SIntrapara"><ol><li><p>Create a small set of random data for input patterns.</p></li><li><p>Generate the weights necessary to properly decode the inputs.</p></li><li><p>Conceive of a way to randomly corrupt the inputs. Perhaps by flipping some bits and show that your network does correctly decode the uncorrupted inputs.</p></li><li><p>Report the accuracy of the output. Explore how the length of the input vector and the number of bits your "flip" impact performance.</p></li></ol></div></p><p><div class="SIntrapara">Detailed instructions:
</div><div class="SIntrapara"><ol><li><p>Make the input patterns 2-d, square and of size "n".</p></li><li><p>Use a bipolar system and have, roughly, equal numbers of +1s and -1s in your patterns.</p></li><li><p>Make a few of them and store them in some sort of data structure.</p></li><li><p>Using those patterns, compute the weight matrix with the following equation:
<div class="math">w_{ij} =\frac{1}{N} \sum_{\mu} value^\mu_i \times value^\mu_j</div>
Where N is the size of the patterns, that is how many "neurons". <span class="math">\mu</span> is an index for each of the patterns, and <span class="math">i</span> and <span class="math">j</span> refer to the neurons in the pattern <span class="math">\mu</span>. Do this <span style="font-weight: bold">in code</span>. The computer is good   for this manual, repetitive sort of stuff.</p></li><li><p>Program an <span style="font-weight: bold">asynchronous</span> updating rule, run your network until it stabilizes, and then show that you get back what you put in.</p></li><li><p>Then do the same for at least one disrupted pattern (where you   flipped a couple of bits around.)</p></li></ol></div></p><h5><a name="(part._ref~3ahopfield)"></a>Hopfield Bibliography</h5><p><table cellspacing="0" cellpadding="0" class="AutoBibliography"><tr><td><p><a name="(autobib._.J..._.J..._.Hopfield.Neural._networks._and._physical._systems._with._emergent._collective._computational._abilities...P.N.A.S._79,._pp..._2554--25581982https~3a//www..pnas..org/doi/abs/10..1073/pnas..79..8..2554)"></a><span class="Autobibentry">J. J. Hopfield. Neural networks and physical systems with emergent collective computational abilities. <span style="font-style: italic">PNAS</span> 79, pp. 2554&ndash;2558, 1982. <a href="https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554"><span class="url">https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554</span></a></span></p></td></tr></table></p><div class="navsetbottom"><span class="navleft"><div class="nosearchform"></div>&nbsp;&nbsp;<span class="tocsettoggle">&nbsp;&nbsp;<a href="javascript:void(0);" title="show/hide table of contents" onclick="TocsetToggle();">contents</a></span></span><span class="navright">&nbsp;&nbsp;<a href="DEs_and_Spikes.html" title="backward to &quot;3 Differential Equations and Spiking Neuron Models&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="index.html" title="up to &quot;Computational Modeling for Psychology&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Projects.html" title="forward to &quot;5 Topics for Final Projects&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div></div></div><div id="contextindicator">&nbsp;</div></body></html>